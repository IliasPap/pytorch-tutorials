{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 MNIST data set handwritten digit recognition\n",
    "\n",
    "## 3.2.1 Data set introduction\n",
    "MNIST includes 60,000 28x28 training samples and 10,000 test samples. Many tutorials will \"start\" with it and almost become a \"model\". It can be said that it is the Hello World in computer vision. So we will also use MNIST for actual combat.\n",
    "\n",
    "When I introduced the convolutional neural network, I mentioned LeNet-5. The reason why LeNet-5 is so powerful is that it increased the recognition rate of MNIST data to 99% in the environment at that time. Here we also build a convolutional neural network from scratch. The network also achieves 99% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Handwritten Digit Recognition\n",
    "First, we define some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=512 #Probably need 2G of video memory\n",
    "EPOCHS=20 # Total training batch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Let torch determine whether to use GPU, it is recommended to use GPU environment, because it will be much faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Pytorch contains the MNIST data set, we can use it directly here.\n",
    "If it is executed for the first time, a data folder will be generated and so it will take some time to download.\n",
    "If it has been downloaded before, it will not be downloaded again\n",
    "\n",
    "Since the official has implemented dataset, DataLoader can be used directly to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a network, that contains two convolutional layers, conv1 and conv2, and then two linear layers as the output, and finally output 10 dimensions. These 10 dimensions are used as 0-9 identifiers to determine the identification Is that number\n",
    "\n",
    "It is recommended that you mark the input and output dimensions of each layer as comments, so that it will be much easier to read the code later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # batch*1*28*28 (each batch of samples will be sent, input channel number 1 (black and white image), image resolution is 28x28)\n",
    "        # The first parameter of the convolutional layer Conv2d below refers to the number of input channels, the second parameter refers to the number of output channels, and the third parameter refers to the size of the convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) # Input channel number 1, output channel number 10, core size 5\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) # The number of input channels is 10, the number of output channels is 20, and the size of the core is 3\n",
    "        # The first parameter of the following fully connected layer Linear refers to the number of input channels, and the second parameter refers to the number of output channels\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) # The number of input channels is 2000, and the number of output channels is 500\n",
    "        self.fc2 = nn.Linear(500, 10) # The number of input channels is 500, and the number of output channels is 10, which means 10 categories\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0) # In this example, in_size=512, which is the value of BATCH_SIZE. The input x can be regarded as a tensor of 512*1*28*28.\n",
    "        out = self.conv1(x) # batch*1*28*28 -> batch*10*24*24 (the 28x28 image undergoes a core convolution of 5x5, and the output becomes 24x24)\n",
    "        out = F.relu(out) # batch*10*24*24 (the activation function ReLU does not change the shape))\n",
    "        out = F.max_pool2d(out, 2, 2) # batch*10*24*24 -> batch*10*12*12 (2*2 pooling layer will be halved)\n",
    "        out = self.conv2(out) # batch*10*12*12 -> batch*20*10*10 (convolution again, the size of the core is 3)\n",
    "        out = F.relu(out) # batch*20*10*10\n",
    "        out = out.view(in_size, -1) # batch*20*10*10 -> batch*2000 (The second dimension of out is -1, which means it is automatically calculated. In this example, the second dimension is 20*10* 10)\n",
    "        out = self.fc1(out) # batch*2000 -> batch*500\n",
    "        out = F.relu(out) # batch*500\n",
    "        out = self.fc2(out) # batch*500 -> batch*10\n",
    "        out = F.log_softmax(out, dim=1) # calculate log(softmax(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a network and use the .to method to move the network to the GPU after instantiation\n",
    "\n",
    "For the optimizer, we also directly choose the simple and violent Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the training function, we will encapsulate all the training operations into this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation of the test is also encapsulated into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # Add a batch of losses\n",
    "            pred = output.max(1, keepdim=True)[1] # Find the subscript with the highest probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s start training, here is the benefit of encapsulation. Just write two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.272529\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.235455\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.101858\n",
      "\n",
      "Test set: Average loss: 0.1018, Accuracy: 9695/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.057989\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.083935\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.051921\n",
      "\n",
      "Test set: Average loss: 0.0523, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.045383\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.049402\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.061366\n",
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.035253\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.038444\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.036877\n",
      "\n",
      "Test set: Average loss: 0.0433, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.038996\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.020670\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.034658\n",
      "\n",
      "Test set: Average loss: 0.0339, Accuracy: 9885/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.067320\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.016328\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.017037\n",
      "\n",
      "Test set: Average loss: 0.0348, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.022150\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.009608\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.012742\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.010173\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.019482\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.012159\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.007792\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.006970\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.004989\n",
      "\n",
      "Test set: Average loss: 0.0294, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.003764\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.005944\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.001866\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [14848/60000 (25%)]\tLoss: 0.002737\n",
      "Train Epoch: 11 [30208/60000 (50%)]\tLoss: 0.014134\n",
      "Train Epoch: 11 [45568/60000 (75%)]\tLoss: 0.001365\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [14848/60000 (25%)]\tLoss: 0.003344\n",
      "Train Epoch: 12 [30208/60000 (50%)]\tLoss: 0.003090\n",
      "Train Epoch: 12 [45568/60000 (75%)]\tLoss: 0.004847\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [14848/60000 (25%)]\tLoss: 0.001278\n",
      "Train Epoch: 13 [30208/60000 (50%)]\tLoss: 0.003016\n",
      "Train Epoch: 13 [45568/60000 (75%)]\tLoss: 0.001328\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [14848/60000 (25%)]\tLoss: 0.002219\n",
      "Train Epoch: 14 [30208/60000 (50%)]\tLoss: 0.003487\n",
      "Train Epoch: 14 [45568/60000 (75%)]\tLoss: 0.014429\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 9896/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [14848/60000 (25%)]\tLoss: 0.003042\n",
      "Train Epoch: 15 [30208/60000 (50%)]\tLoss: 0.002974\n",
      "Train Epoch: 15 [45568/60000 (75%)]\tLoss: 0.000871\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [14848/60000 (25%)]\tLoss: 0.000618\n",
      "Train Epoch: 16 [30208/60000 (50%)]\tLoss: 0.003164\n",
      "Train Epoch: 16 [45568/60000 (75%)]\tLoss: 0.007245\n",
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [14848/60000 (25%)]\tLoss: 0.001874\n",
      "Train Epoch: 17 [30208/60000 (50%)]\tLoss: 0.013951\n",
      "Train Epoch: 17 [45568/60000 (75%)]\tLoss: 0.000729\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 9922/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [14848/60000 (25%)]\tLoss: 0.002581\n",
      "Train Epoch: 18 [30208/60000 (50%)]\tLoss: 0.001396\n",
      "Train Epoch: 18 [45568/60000 (75%)]\tLoss: 0.015521\n",
      "\n",
      "Test set: Average loss: 0.0389, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [14848/60000 (25%)]\tLoss: 0.000283\n",
      "Train Epoch: 19 [30208/60000 (50%)]\tLoss: 0.001385\n",
      "Train Epoch: 19 [45568/60000 (75%)]\tLoss: 0.011184\n",
      "\n",
      "Test set: Average loss: 0.0383, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [14848/60000 (25%)]\tLoss: 0.000472\n",
      "Train Epoch: 20 [30208/60000 (50%)]\tLoss: 0.003306\n",
      "Train Epoch: 20 [45568/60000 (75%)]\tLoss: 0.018017\n",
      "\n",
      "Test set: Average loss: 0.0393, Accuracy: 9899/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s take a look at the results, the accuracy is 99%, no problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model can't even handle MNIST, then your model has no value\n",
    "\n",
    "Even if your model gets MNIST, your model may not have any value\n",
    "\n",
    "MNIST is a very simple data set. Due to its limitations, it can only be used for research purposes and has very limited value for practical applications. But through this example, we can fully understand the workflow of an actual project\n",
    "\n",
    "We find the data set, preprocess the data, define our model, adjust the hyperparameters, test training, and then adjust the hyperparameters or adjust the model through the training results.\n",
    "\n",
    "And through this actual combat, we already have a good template, and future projects can use this template as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}