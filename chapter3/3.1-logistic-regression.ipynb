{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 logistic regression in practice\n",
    "In this chapter, we will deal with structured data and use logistic regression to classify structured data simply.\n",
    "## 3.1.1 Introduction to logistic regression\n",
    "Logistic regression is a kind of generalized linear regression (generalized linear model), which has many similarities with multiple linear regression analysis. Their model forms are basically the same, both have wx + b, where w and b are the parameters to be sought, the difference lies in their different dependent variables, multiple linear regression directly uses wx+b as the dependent variable, that is, y = wx+b , And logistic regression uses the function L to correspond wx+b to a hidden state p, p =L(wx+b), and then determine the value of the dependent variable according to the size of p and 1-p. If L is a logistic function, it is logistic regression, and if L is a polynomial function, it is polynomial regression.\n",
    "\n",
    "To put it more popularly, logistic regression will add a layer of logistic function calls after linear regression.\n",
    "\n",
    "Logistic regression is mainly for two-class prediction. We talked about the Sigmod function in the activation function. The Sigmod function is the most common logistic function, because the output of the Sigmod function is the probability value between 0 and 1, when the probability is greater than 0.5 is predicted as 1, and less than 0.5 is predicted as 0.\n",
    "\n",
    "Let’s use public data to introduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 UCI German Credit Data Set\n",
    "\n",
    "UCI German Credit is UCI's German credit data set, which contains original data and numerical data.\n",
    "\n",
    "The German Credit data is a data set that predicts the tendency to default on loans based on personal bank loan information and overdue loan applications from customers. The data set contains 1000 pieces of data in 24 dimensions.\n",
    "\n",
    "Here we directly use the processed numerical data as a display.\n",
    "\n",
    "[Address](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Code combat\n",
    "The german.data-numeric we use here is that numpy processes the numerical data, we can directly use numpy's load method to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.loadtxt(\"german.data-numeric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is read, we need to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,l=data.shape\n",
    "for j in range(l-1):\n",
    "    meanVal=np.mean(data[:,j])\n",
    "    stdVal=np.std(data[:,j])\n",
    "    data[:,j]=(data[:,j]-meanVal)/stdVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scramble data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinguish between the training set and the test set. Since there is no verification set here, we directly use the accuracy of the test set as the criterion for judging good or bad\n",
    "\n",
    "Distinguishing rules: 900 for training and 100 for testing\n",
    "\n",
    "The format of german.data-numeric is, the first 24 columns are 24 dimensions, and the last one is the label (0, 1) to be marked, so we distinguish the data and the label together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data[:900,:l-1]\n",
    "train_lab=data[:900,l-1]-1\n",
    "test_data=data[900:,:l-1]\n",
    "test_lab=data[900:,l-1]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define the model, the model is very simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR,self).__init__()\n",
    "        self.fc=nn.Linear(24,2) # Since 24 dimensions have been fixed, write 24 here\n",
    "    def forward(self,x):\n",
    "        out=self.fc(x)\n",
    "        out=torch.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pred,lab):\n",
    "    t=pred.max(-1)[1]==lab\n",
    "    return torch.mean(t.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=LR()\n",
    "criterion=nn.CrossEntropyLoss() # Use CrossEntropyLoss loss\n",
    "optm=torch.optim.Adam(net.parameters()) # Adam optimization\n",
    "epochs=1000 # Train 1000 times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100,Loss:0.6313,Accuracy：0.76\n",
      "Epoch:200,Loss:0.6065,Accuracy：0.79\n",
      "Epoch:300,Loss:0.5909,Accuracy：0.80\n",
      "Epoch:400,Loss:0.5801,Accuracy：0.81\n",
      "Epoch:500,Loss:0.5720,Accuracy：0.82\n",
      "Epoch:600,Loss:0.5657,Accuracy：0.81\n",
      "Epoch:700,Loss:0.5606,Accuracy：0.81\n",
      "Epoch:800,Loss:0.5563,Accuracy：0.81\n",
      "Epoch:900,Loss:0.5527,Accuracy：0.81\n",
      "Epoch:1000,Loss:0.5496,Accuracy：0.80\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # Specify the model as training mode and calculate the gradient\n",
    "    net.train()\n",
    "    # Input values ​​need to be converted into torch Tensor\n",
    "    x=torch.from_numpy(train_data).float()\n",
    "    y=torch.from_numpy(train_lab).long()\n",
    "    y_hat=net(x)\n",
    "    loss=criterion(y_hat,y) # calculate loss\n",
    "    optm.zero_grad() # Clear the loss of the previous step\n",
    "    loss.backward() # Backpropagation\n",
    "    optm.step() # optimization\n",
    "    if (i+1)%100 == 0: # Here we output relevant information every 100 times\n",
    "        # Specify the model as calculation mode\n",
    "        net.eval()\n",
    "        test_in=torch.from_numpy(test_data).float()\n",
    "        test_l=torch.from_numpy(test_lab).long()\n",
    "        test_out=net(test_in)\n",
    "        # Use our test function to calculate accuracy\n",
    "        accu=test(test_out,test_l)\n",
    "        print(\"Epoch:{},Loss:{:.4f},Accuracy:{:.2f}\".format(i+1,loss.item(),accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is complete, our accuracy reached ~ 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}