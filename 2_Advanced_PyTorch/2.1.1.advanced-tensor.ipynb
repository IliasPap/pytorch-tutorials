{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch basics: tensor\n",
    "In the first chapter, we have got a certain understanding of PyTorch through the official introductory tutorial.\n",
    "This chapter will introduce the basic knowledge of PyTorch in detail.\n",
    "After you have mastered all these basic knowledge, you can advance more quickly in the following applications.\n",
    "If you already have a certain understanding of PyTorch, you can skip this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'1.6.0'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First introduce relevant packages\n",
    "import torch\n",
    "#Print the version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "As we describe in the previous chapter, Tensor is the basic operation unit in PyTorch.\n",
    "It is the same as Numpy's ndarray and represents a multi-dimensional matrix.\n",
    "The biggest difference with ndarray is that PyTorch's Tensor can run on the GPU, while numpy's ndarray can only\n",
    "run on the CPU. Running on the GPU greatly speeds up the calculation.\n",
    "\n",
    "Below we generate a simple tensor\n",
    "Let's remind some of the basic operations we introduced earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9496, 0.0326, 0.3999],\n        [0.0020, 0.4833, 0.2879]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above generated a matrix with 2 rows and 3 columns. Let's take a look at its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# You can use the same shape attribute as numpy to view\n",
    "print(x.shape)\n",
    "# You can also use the size() function, and the returned results are the same\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor is a multiple linear mapping defined on the Cartesian product of some vector spaces and some dual spaces.\n",
    "Its coordinates are in |n|-dimensional space and a quantity with |n| components,\n",
    "where each  component is a function of coordinates, and during coordinate transformation,\n",
    "these components are also linearly transformed according to certain rules.\n",
    "`r` is called the rank or order of the tensor (it has nothing to do with the rank and order of the matrix).\n",
    "\n",
    "\n",
    "Let's generate some multi-dimensional tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[0.1113, 0.4576, 0.3505, 0.2163, 0.5974],\n          [0.4168, 0.4367, 0.5905, 0.1329, 0.8768],\n          [0.5438, 0.3995, 0.8157, 0.2431, 0.1530],\n          [0.0769, 0.3518, 0.3402, 0.1221, 0.3782]],\n\n         [[0.1837, 0.3494, 0.1018, 0.9510, 0.6622],\n          [0.0245, 0.0653, 0.6239, 0.4605, 0.2148],\n          [0.0454, 0.3152, 0.9159, 0.3637, 0.8430],\n          [0.6172, 0.4760, 0.4793, 0.5420, 0.1138]],\n\n         [[0.9328, 0.3753, 0.2443, 0.6955, 0.8851],\n          [0.5093, 0.1555, 0.6289, 0.6393, 0.8007],\n          [0.5360, 0.7304, 0.5552, 0.3395, 0.1447],\n          [0.4943, 0.2452, 0.3733, 0.5279, 0.5821]]],\n\n\n        [[[0.7804, 0.5914, 0.0171, 0.2303, 0.1721],\n          [0.9945, 0.4262, 0.7082, 0.3607, 0.8928],\n          [0.0435, 0.2055, 0.8312, 0.3665, 0.9429],\n          [0.8926, 0.9582, 0.3987, 0.0273, 0.4337]],\n\n         [[0.6620, 0.1160, 0.8962, 0.2837, 0.0875],\n          [0.6393, 0.3094, 0.0861, 0.7500, 0.5613],\n          [0.2152, 0.2831, 0.5173, 0.9583, 0.1084],\n          [0.0695, 0.5977, 0.0081, 0.7044, 0.4630]],\n\n         [[0.4169, 0.2996, 0.5426, 0.5094, 0.2868],\n          [0.2484, 0.1911, 0.4430, 0.4873, 0.3525],\n          [0.2075, 0.5380, 0.0116, 0.8706, 0.3235],\n          [0.1625, 0.5212, 0.9575, 0.7072, 0.6278]]]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.rand(2,3,4,5)\n",
    "print(y.size())\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zeroth order tensor (r = 0) is a scalar ,\n",
    "the first order tensor (r = 1) is a vector\n",
    "and the second order tensor (r = 2) is a matrix while\n",
    "the third order and above tensors (r >= 3) are  called a multi-dimensional tensors.\n",
    "\n",
    "One thing to pay special attention to is the scalars:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1433)\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We directly use existing digital generation\n",
    "scalar = torch.tensor(3.1433223)\n",
    "print(scalar)\n",
    "#Print scalar size\n",
    "scalar.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scalars, we can directly use `.item()` to retrieve the value of the corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "3.143322229385376"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pay attention: If the tensor is initialised  with a list only one element in the tensor\n",
    "we can also call the `tensor.item()` method. The only difference now is the size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([3.1433223])\n",
    "tensor.item()\n",
    "tensor.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic types\n",
    "There are five basic data types of Tensor:\n",
    "- 32-bit floating point type: `torch.FloatTensor`. (default)\n",
    "- 64-bit integer: `torch.LongTensor`.\n",
    "- 32-bit integer: `torch.IntTensor`.\n",
    "- 16-bit integer: `torch.ShortTensor`.\n",
    "- 64-bit floating point type: `torch.DoubleTensor`.\n",
    "\n",
    "In addition to the above number types, there are\n",
    "`torch.ByteTensor` (8-bit) and `torch.CharTensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = tensor.long()\n",
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.1426], dtype=torch.float16)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half = tensor.half()\n",
    "half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3], dtype=torch.int32)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_t=tensor.int()\n",
    "int_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.1433])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flo = tensor.float()\n",
    "flo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3], dtype=torch.int16)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short = tensor.short()\n",
    "short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3], dtype=torch.int8)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = tensor.char()\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3], dtype=torch.uint8)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = tensor.byte()\n",
    "bt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy conversion\n",
    "Use numpy method to convert Tensor to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0753376  -0.08061682]\n",
      " [ 1.1077912  -0.92455935]\n",
      " [-0.14099053  0.354406  ]]\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((3, 2))\n",
    "# tensor converted to numpy\n",
    "numpy_a = a.numpy()\n",
    "print(numpy_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numpy to Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.0753, -0.0806],\n        [ 1.1078, -0.9246],\n        [-0.1410,  0.3544]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a = torch.from_numpy(numpy_a)\n",
    "torch_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor and numpy objects share the same memory, so the conversion between them is fast and consumes almost no resources.\n",
    "But this also means that if one of them changes, the other will also change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch between devices\n",
    "Under normal circumstances, you can use the .cuda method to move tensor to gpu. This step requires cuda device support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.FloatTensor'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_a=torch.rand(4, 3)\n",
    "cpu_a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.cuda.FloatTensor'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_a=cpu_a.cuda()\n",
    "gpu_a.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.cpu()` method to move tensor to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.FloatTensor'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_b=gpu_a.cpu()\n",
    "cpu_b.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have multiple GPUs, we can use the to method to determine which device to use with `torch.device(cuda:device_id)`\n",
    ". Here is just a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "'torch.cuda.FloatTensor'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use torch.cuda.is_available() to determine if there is a cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#Transfer tensor to device\n",
    "gpu_b=cpu_b.to(device)\n",
    "gpu_b.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "There are many  initialization methods available in Pytorch.\n",
    "Let's see the random initialization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1370, 0.3020, 0.2490],\n        [0.9052, 0.1449, 0.8814],\n        [0.6225, 0.1218, 0.7992],\n        [0.1710, 0.5384, 0.5160],\n        [0.5533, 0.9356, 0.8533]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use [0,1] to initialize a two-dimensional array randomly\n",
    "rnd = torch.rand(5, 3)\n",
    "rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To initialize a tensor with ones (1) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Initialize, use 1 to fill\n",
    "one = torch.ones(2, 2)\n",
    "one\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and zeros as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.],\n        [0., 0.]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "##Initialization, fill with 0\n",
    "zero=torch.zeros(2,2)\n",
    "zero"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create an identity matrix where only the diagonal elements are equal to 1\n",
    "and the rest equal to 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0.],\n        [0., 1.]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize an identity matrix, that is, the diagonal is 1 and the others are 0\n",
    "eye=torch.eye(2,2)\n",
    "eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common methods\n",
    "The operations API for tensors  is very similar to NumPy. If you are familiar with the operations in NumPy,\n",
    "then they are basically the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1391,  0.4317,  1.6309],\n        [-1.2231, -1.0626,  0.6486],\n        [ 0.3765, -1.5161,  0.6124]])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6309, 0.6486, 0.6124]) tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Take the maximum value along the line\n",
    "max_value, max_idx = torch.max(x, dim=1)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.2017, -1.6371, -0.5272])\n"
     ]
    }
   ],
   "source": [
    "# Each row x sum\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3469,  3.2753,  0.1466],\n",
      "        [-2.9494, -1.9053, -2.0406],\n",
      "        [ 3.0602, -0.8539,  1.2648]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randn(3, 3)\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reshape tensors\n",
    " If you want to resize/reshape tensor, you can use ``torch.view`` or ``torch.reshape``:\n",
    "\n",
    "We use the reshape function to change the shape of one (possibly multi-dimensional) array,\n",
    "to another that contains the\n",
    "same number of elements. For example, we can transform the shape of our line vector x to (3, 4),\n",
    "which contains the same values but interprets them as a matrix containing 3 rows and 4 columns.\n",
    "Note that although the shape has changed, the elements in x have not.\n",
    "\n",
    "Fortunately, PyTorch can automatically work out one dimension given the other.\n",
    "We can invoke this capability by placing -1 for the dimension that we would like PyTorch to automatically infer.\n",
    "In our case, instead of ``x.reshape((2, 8))``,\n",
    "we could have equivalently used ``x.reshape((-1, 8))`` or ``x.reshape((2, -1))``\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "x = x.reshape((2, 8))\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change tensor axis\n",
    "``view`` and ``permute`` are slightly different operations.\n",
    "``view`` changes the order of the tensors whereas ``permute`` only changes the axis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., 2., 3.],[4., 5., 6.]])\n",
    "\n",
    "x.view(3, -1)\n",
    "\n",
    "x.permute(1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove or add a fake dimension with ```squeeze() ``` and  ```unsqueeze() ``` operations, respectively.\n",
    "\n",
    "```squeeze() ``` removes all 1-dimensional parts from a tensor and\n",
    "```squeeze(0) ``` removes the first dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., 2., 3., 4., 5.]])\n",
    "print(x.squeeze(0).shape)\n",
    "print(x.unsqueeze(0).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "## Advanced operations on Tensors\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the sum of values in a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1062)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "torch.sum(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the mean value of a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0118)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the standard deviation value of a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.2474)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get e^x values for a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4541, 0.1434, 1.7414],\n        [5.8515, 4.4039, 0.2557],\n        [0.6661, 1.8219, 1.2265]])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find min/max value in a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.7667)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-1.9422)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indices of min and max values of a tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(3)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Concatenation**\n",
    "\n",
    "is another important operation that you need in your toolbox.\n",
    "Two tensors of the same size on all the dimensions except one, if required, can be concatenated using ```torch.cat```."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7894, -1.9422,  0.5547],\n        [ 1.7667,  1.4825, -1.3638],\n        [-0.4064,  0.5999,  0.2042],\n        [-0.7894, -1.9422,  0.5547],\n        [ 1.7667,  1.4825, -1.3638],\n        [-0.4064,  0.5999,  0.2042]])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate along second dimension ```dim=1 ```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7894, -1.9422,  0.5547, -0.7894, -1.9422,  0.5547],\n        [ 1.7667,  1.4825, -1.3638,  1.7667,  1.4825, -1.3638],\n        [-0.4064,  0.5999,  0.2042, -0.4064,  0.5999,  0.2042]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,x), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " **Stack operation**:\n",
    "looks very similar to concatenation but it is an entirely different operation.\n",
    "If you want to add a new dimension to your tensor, ```torch.stack()``` is the way to go.\n",
    "Similar to cat, you can pass the axis where you want to add the new dimension.\n",
    "However, make sure all the dimensions of the two tensors are the same other than the attaching dimension."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.7894, -1.9422,  0.5547],\n         [ 1.7667,  1.4825, -1.3638],\n         [-0.4064,  0.5999,  0.2042]],\n\n        [[-0.7894, -1.9422,  0.5547],\n         [ 1.7667,  1.4825, -1.3638],\n         [-0.4064,  0.5999,  0.2042]]])"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((x,x), dim=0)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basic operations of tensors are almost introduced.\n",
    "The next chapter introduces PyTorch's automatic derivative mechanism (autograd).\n",
    "\n",
    "##### Useful links\n",
    "https://towardsdatascience.com/how-to-train-your-neural-net-tensors-and-autograd-941f2c4cc77c\n",
    "\n",
    "https://www.codementor.io/@packt/how-to-perform-basic-operations-in-pytorch-code-10al39a4c4\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/how-to-train-your-neural-net-tensors-and-autograd-941f2c4cc77c"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}