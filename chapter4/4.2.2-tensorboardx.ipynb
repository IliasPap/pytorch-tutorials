{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models,datasets\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 Use Tensorboard for visualization in PyTorch\n",
    "\n",
    "## Introduction to Tensorboard\n",
    "Tensorboard is a built-in visualization tool of tensorflow. It makes the understanding, debugging and optimization of tensorflow program easier and more efficient by visualizing the information of the log file output by the tensorflow program.\n",
    "The visualization of Tensorboard relies on the log files output by the tensorflow program, so tensorboard and tensorflow programs run in different processes.\n",
    "TensorBoard provides us with an extremely convenient and powerful visualization environment. It can help us understand the entire neural network learning process, data distribution, performance bottlenecks, and so on.\n",
    "\n",
    "Although tensorboard is a built-in visualization tool of tensorflow, they run in different processes, so there are already great gods on Github who have applied tensorboard to Pytorch [link here]( https://github.com/lanpa/tensorboardX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard installation\n",
    "First need to install tensorboard\n",
    "\n",
    "`pip install tensorboard`\n",
    "\n",
    "\n",
    "\n",
    "~~ Then install tensorboardx ~~\n",
    "\n",
    "~~ `pip install tensorboardx` ~~\n",
    "pytorch 1.1 and later versions have built-in SummaryWriter function, so there is no need to install tensorboardx\n",
    "\n",
    "After the installation is complete, execute independent commands like visdom\n",
    "`tensorboard --logdir logs` can be started, the default port is 6006, open `http://localhost:6006/` in the browser to see the web page.\n",
    "\n",
    "What I want to explain here is that the Microsoft Edge browser css will not load, and it will be displayed normally using chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page\n",
    "Unlike visdom, tensorboard artificially distinguishes multiple tags for different types, and each tag page represents a different type.\n",
    "Below we will give a brief introduction based on different page functions. For more details, please refer to the official website\n",
    "### SCALAR\n",
    "Summarize and record scalar data, usually used to visualize the accuracy (val acc), loss value (train/test loss), learning rate, weight and bias of each layer during the training process. The change curve of statistics (mean, std, max/min), etc.\n",
    "### IMAGES\n",
    "Visualize the training/test images or feature maps used in the current round of training\n",
    "### GRAPHS\n",
    "Visualize the structure of the calculation graph and the information on the calculation graph, usually used to show the structure of the network\n",
    "### HISTOGRAMS\n",
    "Visualize the value distribution of the tensor and record the histogram of the variables (the statistical tensor changes with the number of iterations)\n",
    "### PROJECTOR\n",
    "Full name Embedding Projector high-dimensional vector for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use\n",
    "Before use, please confirm the execution of `tensorboard --logdir logs` and ensure that the `http://localhost:6006/` page can be opened normally\n",
    "\n",
    "### Image display\n",
    "First introduce the relatively simple functions, check the images in our training set and data set, here we use ready-made images as a display. Here is a picture of a cat on wikipedia [here](https://en.wikipedia.org/wiki/Cat#/media/File:Felis_silvestris_catus_lying_on_rice_straw.jpg)\n",
    "\n",
    "Introduce the tensorboardX package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The references here should also be modified to torch references\n",
    "#from tensorboardX import SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 853)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_img = Image.open('./1280px-Felis_silvestris_catus_lying_on_rice_straw.jpg')\n",
    "cat_img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 1280x853 picture, let’s change her into a 224x224 picture first, because vgg16 will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_224 = transforms.Compose([\n",
    "        transforms.Resize(224), # Here to explain that Scale has expired, use Resize\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "cat_img_224=transform_224(cat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show pictures in tebsorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='./logs', comment='cat image') # The logs here should be the same as the parameters of --logdir\n",
    "writer.add_image(\"cat\",cat_img_224)\n",
    "writer.close()# Perform close refresh immediately, otherwise it will refresh automatically every 120 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browser visit `http://localhost:6006/#images` to see the picture of the cat\n",
    "### Update loss function\n",
    "To update the loss function and training batches, we use the same simulation display as visdom. Here is the SCALAR page of tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([100])\n",
    "y = torch.FloatTensor([500])\n",
    "\n",
    "for epoch in range(30):\n",
    "    x = x * 1.2\n",
    "    y = y / 1.1\n",
    "    loss = np.random.random()\n",
    "    with SummaryWriter(log_dir='./logs', comment='train') as writer: #You can use python's with syntax directly and automatically call the close method\n",
    "        writer.add_histogram('his/x', x, epoch)\n",
    "        writer.add_histogram('his/y', y, epoch)\n",
    "        writer.add_scalar('data/x', x, epoch)\n",
    "        writer.add_scalar('data/y', y, epoch)\n",
    "        writer.add_scalar('data/loss', loss, epoch)\n",
    "        writer.add_scalars('data/data_group', {'x': x,\n",
    "                                                'y': y}, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browser visit `http://localhost:6006/#scalars` to see the graph\n",
    "### Use PROJECTOR to visualize high-dimensional vectors\n",
    "The principle of PROJECTOR is to project high-dimensional vectors to a three-dimensional coordinate system (dimension reduction) through PCA, T-SNE and other methods. Embedding Projector reads data from the checkpoint file saved during the running of the model. By default, principal component analysis (PCA) is used to project high-dimensional data into 3D space. You can also select the T-SNE projection method by setting the settings, here is one Simple display.\n",
    "\n",
    "We still use the mnist code from Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "EPOCHS=20\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(20*10*10,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2) #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out\n",
    "model = ConvNet()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    n_iter=0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            n_iter=n_iter+1\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            #相对于以前的训练方法 主要增加了以下内容\n",
    "            out = torch.cat((output.data, torch.ones(len(output), 1)), 1) # 因为是投影到3D的空间，所以我们只需要3个维度\n",
    "            with SummaryWriter(log_dir='./logs', comment='mnist') as writer: \n",
    "                #使用add_embedding方法进行可视化展示\n",
    "                writer.add_embedding(\n",
    "                    out,\n",
    "                    metadata=target.data,\n",
    "                    label_img=data.data,\n",
    "                    global_step=n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里节省时间，只训练一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [14848/60000 (25%)]\tLoss: 0.352312\n",
      "Train Epoch: 0 [30208/60000 (50%)]\tLoss: 0.202950\n",
      "Train Epoch: 0 [45568/60000 (75%)]\tLoss: 0.156494\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打开 `http://localhost:6006/#projector` 即可看到效果。\n",
    "\n",
    "目前测试投影这部分也是有问题的，根据官网文档的代码进行测试，也显示不出来，正在找原因\n",
    "\n",
    "### 绘制网络结构\n",
    "在pytorch中我们可以使用print直接打印出网络的结构，但是这种方法可视化效果不好，这里使用tensorboard的GRAPHS来实现网络结构的可视化。\n",
    "由于pytorch使用的是动态图计算，所以我们这里要手动进行一次前向的传播.\n",
    "\n",
    "使用Pytorch已经构建好的模型进行展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True) # 这里下载预训练好的模型\n",
    "print(vgg16) # 打印一下这个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前向传播前，先要把图片做一些调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_2 = transforms.Compose([\n",
    "    transforms.Resize(224), \n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用上一张猫的图片进行前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_input=transform_2(cat_img)[np.newaxis]# 因为pytorch的是分批次进行的，所以我们这里建立一个批次为1的数据集\n",
    "vgg16_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始前向传播，打印输出值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = vgg16(vgg16_input)\n",
    "_, preds = torch.max(out.data, 1)\n",
    "label=preds.numpy()[0]\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将结构图在tensorboard进行展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(log_dir='./logs', comment='vgg161') as writer:\n",
    "    writer.add_graph(vgg16, vgg16_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Pytorch的1.3版本来说，实测 SummaryWriter在处理结构图的时候是有问题的（或者是需要加什么参数，目前我还没找到），所以建议大家继续使用tensorboardx。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    n_iter=0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0:\n",
    "            n_iter=n_iter+1\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            #Compared to the previous training method, the following content is mainly added\n",
    "            out = torch.cat((output.data, torch.ones(len(output), 1)), 1) # Because it is projected into 3D space, so we only need 3 dimensions\n",
    "            with SummaryWriter(log_dir='./logs', comment='mnist') as writer:\n",
    "                #Use add_embedding method for visual display\n",
    "                writer.add_embedding(\n",
    "                    out,\n",
    "                    metadata=target.data,\n",
    "                    label_img=data.data,\n",
    "                    global_step=n_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save time here, only train once"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Open `http://localhost:6006/#projector` to see the effect.\n",
    "\n",
    "At present, there is a problem with the test projection. According to the code of the official website document, it can’t be displayed. I am looking for the reason.\n",
    "\n",
    "### Draw network structure\n",
    "In pytorch, we can use print to directly print out the structure of the network, but this method has a poor visualization effect. Here we use GRAPHS of tensorboard to visualize the network structure.\n",
    "Since pytorch uses dynamic graph calculation, we have to manually perform a forward propagation here.\n",
    "\n",
    "Use Pytorch's built model for display"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True) # download the pretrained model here\n",
    "print(vgg16) # Print this model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before forwarding, make some adjustments to the picture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_2 = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the previous cat picture for forward propagation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg16_input=transform_2(cat_img)[np.newaxis]# Because pytorch is carried out in batches, we will create a data set with batch 1 here\n",
    "vgg16_input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start forward propagation, print out the value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = vgg16(vgg16_input)\n",
    "_, preds = torch.max(out.data, 1)\n",
    "label=preds.numpy()[0]\n",
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the structure diagram on tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with SummaryWriter(log_dir='./logs', comment='vgg161') as writer:\n",
    "    writer.add_graph(vgg16, vgg16_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the 1.3 version of Pytorch, the measured SummaryWriter has problems when processing the structure diagram (or what parameters need to be added, I haven't found it yet), so I suggest you continue to use tensorboardx."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep learning",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}