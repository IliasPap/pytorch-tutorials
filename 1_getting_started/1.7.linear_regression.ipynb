{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb362247d68>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "useful links\n",
    "\n",
    "https://www.youtube.com/watch?v=zPG4NjIkCjc\n",
    "\n",
    "https://www.kaggle.com/aakashns/pytorch-basics-linear-regression-from-scratch\n",
    "\n",
    "Linear regression models a linear relationship between two variables. There is usually an independent value $x$\n",
    "and a dependent value $y$. Linear regression has an equation with the form $y=ax+b$ and finds the optimal values\n",
    "$a$ and $b$ that best describe the relationship of the variables. More specifically, this equation describes a straight\n",
    "line with slope eaual to $a$ and $b$ the intercept (the value of $y$ when $x = 0$).\n",
    "\n",
    "\n",
    "\n",
    "Let's create and initialize randomly our model's variables  $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5410], requires_grad=True)\n",
      "tensor([-0.2934], requires_grad=True)\n",
      "tensor([-3.6509], grad_fn=<AddBackward0>) tensor([-2.1788])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.randn(1,requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "x = torch.randn(1)\n",
    "y = a*x+b\n",
    "\n",
    "y.backward()\n",
    "print(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fit simple line\n",
    "\n",
    "Let's create dummy data and try to fit our linear regression model. We'll initialize randomly our a,b and try to run\n",
    "some iterations to find the optimal weights that fi oour following line.\n",
    "\n",
    "$y=2x+0.5$\n",
    "\n",
    "Now let's create our data and  fit our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "torch.Size([10, 1])\n",
      "tensor([[ 2.5000],\n",
      "        [ 4.5000],\n",
      "        [ 6.5000],\n",
      "        [ 8.5000],\n",
      "        [10.5000],\n",
      "        [12.5000],\n",
      "        [14.5000],\n",
      "        [16.5000],\n",
      "        [18.5000],\n",
      "        [20.5000]])\n",
      "tensor([[-0.5161],\n",
      "        [ 0.0523],\n",
      "        [ 0.6208],\n",
      "        [ 1.1892],\n",
      "        [ 1.7576],\n",
      "        [ 2.3261],\n",
      "        [ 2.8945],\n",
      "        [ 3.4629],\n",
      "        [ 4.0314],\n",
      "        [ 4.5998]], grad_fn=<AddBackward0>)\n",
      "tensor(106.3641, grad_fn=<MeanBackward0>)\n",
      "tensor([[0.5684]], requires_grad=True)\n",
      "tensor([[-127.6605]])\n",
      "tensor([-1.0845], requires_grad=True)\n",
      "tensor([-18.9163])\n",
      "tensor([[0.]])\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.randn((1,1),requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "\n",
    "def model(x):\n",
    "    return x @ a.t() + b\n",
    "\n",
    "# MSE loss\n",
    "# def mse(t1, t2):\n",
    "#     diff = t1 - t2\n",
    "#     return torch.sum(diff * diff) / diff.numel()\n",
    "def mse(y,y_hat):\n",
    "     return((y-y_hat)**2).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs = torch.range(1,10).float().unsqueeze(-1)\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "targets = 2. * torch.range(1,10).float().unsqueeze(-1) + 0.5*torch.ones(10,1)\n",
    "print(targets.shape)\n",
    "print(targets)\n",
    "preds = model(inputs)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "# Gradients for weights\n",
    "print(a)\n",
    "print(a.grad)\n",
    "\n",
    "\n",
    "\n",
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)\n",
    "\n",
    "\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's train the model for 100 iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Done\n",
      "a = tensor([[2.1856]], requires_grad=True) b = tensor([-0.7955], requires_grad=True)\n",
      "Predictions tensor([[ 1.3901],\n",
      "        [ 3.5757],\n",
      "        [ 5.7614],\n",
      "        [ 7.9470],\n",
      "        [10.1326],\n",
      "        [12.3182],\n",
      "        [14.5039],\n",
      "        [16.6895],\n",
      "        [18.8751],\n",
      "        [21.0607]], grad_fn=<AddBackward0>)\n",
      "Loss = 0.3596566319465637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train for 100 epochs\n",
    "lr = 1e-3\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    loss = mse(preds, targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        a.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print('Optimization Done')\n",
    "print(f'a = {a} b = {b}')\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(f'Predictions {preds}')\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(f'Loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run linear regression with multidimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "(5, 2)\n",
      "tensor([[ -38.8561, -106.0418],\n",
      "        [ -37.9619, -139.9880],\n",
      "        [ -18.8418, -152.0850],\n",
      "        [ -94.1238, -113.6402],\n",
      "        [   1.0621, -130.9709]], grad_fn=<AddBackward0>)\n",
      "tensor(32154.3379, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.3986,  0.4033,  0.8380],\n",
      "        [-0.7193, -0.4033, -0.5966]], requires_grad=True)\n",
      "tensor([[ -9724.1221, -10014.8340,  -6223.8867],\n",
      "        [-18439.3301, -20335.5742, -12519.9219]])\n",
      "tensor([ 0.1820, -0.8567], requires_grad=True)\n",
      "tensor([-113.9443, -220.5452])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "a = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')\n",
    "\n",
    "\n",
    "# # Input (temp, rainfall, humidity)\n",
    "# inputs = 0.001*np.array([[73 ], \n",
    "#                    [91 ], \n",
    "#                    [87], \n",
    "#                    [102], \n",
    "#                    [69]], dtype='float32')\n",
    "\n",
    "# # Targets (apples, oranges)\n",
    "# targets = 0.001*np.array([[56], \n",
    "#                     [81], \n",
    "#                     [119], \n",
    "#                     [22], \n",
    "#                     [103]], dtype='float32')\n",
    "\n",
    "# Convert inputs and targets to tensors\n",
    "\n",
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ a.t() + b\n",
    "\n",
    "# MSE loss\n",
    "\n",
    "def mse(y,y_hat):\n",
    "     return((y-y_hat)**2).mean()\n",
    "\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "# Gradients for weights\n",
    "print(a)\n",
    "print(a.grad)\n",
    "\n",
    "\n",
    "\n",
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)\n",
    "\n",
    "\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(a.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Iterate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 32154.34\n",
      "Loss 9129929.00\n",
      "Loss 2610502400.00\n",
      "Loss 746420764672.00\n",
      "Loss 213424055255040.00\n",
      "Loss 61024338450579456.00\n",
      "Loss 17448686582851698688.00\n",
      "Loss 4989102303899824422912.00\n",
      "Loss 1426534277232024658903040.00\n",
      "Loss 407888870934643492467507200.00\n",
      "Loss 116627652230322923310191476736.00\n",
      "Loss 33347338636072866334230678863872.00\n",
      "Loss 9535003514718354129369510547816448.00\n",
      "Loss 2726342801076504172003317441493991424.00\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss inf\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "lr = 1e-3\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    #print(f'Loss {loss.item():.2f}')\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        a.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = Linear_regression_model()\n",
    "# num_of_iterations = 100\n",
    "# for i in range(num_of_iterations):\n",
    "#     y_hat =model.forward(x)\n",
    "#     loss = model.mse_loss(y,y_hat)\n",
    "#     print(f'LOSS {loss}')\n",
    "#     model.update_params()\n",
    "\n",
    "\n",
    "# x1 = torch.randn(10,1)\n",
    "#\n",
    "# x = torch.tensor(x1)\n",
    "#\n",
    "# y = torch.randn(10,1)\n",
    "#\n",
    "#\n",
    "#\n",
    "# a = torch.randn(1,1,requires_grad=True)\n",
    "# b = torch.randn(1,requires_grad=True)\n",
    "# num_of_iterations = 100\n",
    "# for i in range(num_of_iterations):\n",
    "#     y_hat = x@a.t() + b\n",
    "#     loss = ((y-y_hat)**2).mean()\n",
    "#     print(f'LOSS {loss.item()}')\n",
    "#     loss.backward()\n",
    "#\n",
    "#     a = a-lr*a.grad\n",
    "#     b = b-lr*b.grad\n",
    "#     if a.grad is not None:\n",
    "#         a.grad.zero_()\n",
    "#     if b.grad is not None:\n",
    "#         b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n",
      "Loss nan\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "lr = 1e-3\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    print(f'Loss {loss.item():.2f}')\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        a.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Linear Regression model using PyTorch built in Functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  after removing the cwd from sys.path.\n",
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026713624596595764\n",
      "tensor([[2.0499]])\n",
      "tensor([0.1472])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = torch.range(1,10).float().unsqueeze(-1)\n",
    "#print(inputs.shape)\n",
    "#print(inputs)\n",
    "targets = 2. * torch.range(1,10).float().unsqueeze(-1) + 0.5*torch.ones(10,1)\n",
    "#print(targets.shape)\n",
    "\n",
    "lr_model = nn.Linear(in_features=1,out_features=1)\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss(size_average=True)\n",
    "for i in range(100):\n",
    "    preds = lr_model(inputs)\n",
    "    loss = criterion(preds,targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "print(loss.item())\n",
    "print(lr_model.weight.data)\n",
    "print(lr_model.bias.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Wine Quality dataset\n",
    "\n",
    "- Read Data\n",
    "- Create Dataloader\n",
    "- Model\n",
    "- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7fb2c3ddc6d8>\n",
      "torch.Size([1599, 12])\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "tensor([[5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        ...,\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.]])\n",
      "torch.Size([1599, 11])\n",
      "torch.Size([1599, 1])\n",
      "12.68463984131813\n",
      "6.692981839179993\n",
      "5.26429982483387\n",
      "4.2506261467933655\n",
      "3.4865940511226654\n",
      "2.9260557740926743\n",
      "2.506434954702854\n",
      "2.1743488386273384\n",
      "1.9196989461779594\n",
      "1.7100230306386948\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_wine_data():\n",
    "    with open('./data/winequality-red.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        print(csv_reader)\n",
    "        line_count = 0\n",
    "        wine_data = []\n",
    "        categories = []\n",
    "        for idx,row in enumerate(csv_reader):\n",
    "            #print(row)\n",
    "            if idx ==0 :\n",
    "                categories = row\n",
    "            else:\n",
    "\n",
    "\n",
    "                r = list(map(float, row))\n",
    "                wine_data.append(r)\n",
    "        data_tensor = torch.tensor(wine_data)\n",
    "    return data_tensor,categories\n",
    "\n",
    "\n",
    "data_tensor,categories = read_wine_data()\n",
    "#results = list(map(int, results))\n",
    "print(data_tensor.shape)\n",
    "print(categories)\n",
    "inputs = data_tensor[:,:-1]\n",
    "targets = data_tensor[:,-1].unsqueeze(-1)\n",
    "print(targets)\n",
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "#results = list(map(int, results))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_model = nn.Linear(in_features=11,out_features=1)\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.0001)\n",
    "criterion = nn.MSELoss(size_average=True)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "#print(train_ds[0:3])\n",
    "# Define data loader\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "#next(iter(train_dl))\n",
    "\n",
    "# Define dataset\n",
    "\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    average_loss = 0.0\n",
    "    for batch_index, (x,y) in enumerate(train_dl):\n",
    "        preds = lr_model(x)\n",
    "        loss = criterion(preds,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        average_loss +=loss.item()\n",
    "    print(average_loss/len(train_dl))\n",
    "    #print(lr_model.weight.data)\n",
    "    #print(lr_model.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}