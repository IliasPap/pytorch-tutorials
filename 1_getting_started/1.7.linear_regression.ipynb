{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Bn6a7tTaR9w",
    "outputId": "02ce2649-5a84-4431-e503-b678a3e36f42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faf33f9dd68>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Z6sEB4YaR9-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "useful links\n",
    "![Linear_regression_img](./figures/1.7.linear_regression.png)\n",
    "\n",
    "https://www.youtube.com/watch?v=zPG4NjIkCjc\n",
    "\n",
    "https://www.kaggle.com/aakashns/pytorch-basics-linear-regression-from-scratch\n",
    "\n",
    "Linear regression models a linear relationship between two variables. There is usually an independent value $x$\n",
    "and a dependent value $y$. Linear regression has an equation with the form $y=ax+b$ and finds the optimal values\n",
    "$a$ and $b$ that best describe the relationship of the variables. More specifically, this equation describes a straight\n",
    "line with slope eaual to $a$ and $b$ the intercept (the value of $y$ when $x = 0$).\n",
    "\n",
    "\n",
    "\n",
    "Let's create and initialize randomly our model's variables  $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgQ5q7oTaR9_",
    "outputId": "4ff1d2b6-8d49-420a-d81f-3b544000fbd6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5410], requires_grad=True)\n",
      "tensor([-0.2934], requires_grad=True)\n",
      "tensor([-3.6509], grad_fn=<AddBackward0>) tensor([-2.1788])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.randn(1,requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "x = torch.randn(1)\n",
    "y = a*x+b\n",
    "\n",
    "y.backward()\n",
    "print(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKMOmY6EaR-J",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fitting a simple line\n",
    "\n",
    "Let's create a simple dataset and try to fit our linear regression model. We'll initialize randomly our a,b and try to run\n",
    "some iterations to find the optimal weights that fi oour following line.\n",
    "\n",
    "$y=2x+0.5$\n",
    "\n",
    "Now let's create our data and fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJRBkGbRaR-L",
    "outputId": "27ca2ebc-f61b-4b6a-b33b-90dbaf4b915a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "a = torch.randn((1,1),requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "\n",
    "def model(x):\n",
    "    return x @ a.t() + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MSE LOSS\n",
    "Mean Squared Error (MSE) or mean squared deviation (MSD) of an estimator\n",
    "(of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors.\n",
    "\n",
    "$MSE(y,\\hat {y}) =\\sum_{i=1}^{N} (y_{i}-\\hat{y}_{i})^{2} $\n",
    "\n",
    "In other words MSE is the mean ${ \\left({\\frac {1}{n}}\\sum _{i=1}^{n}\\right)}$\n",
    "of the squares of the errors ${ (y_{i}-{\\hat {y_{i}}})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mse(y,y_hat):\n",
    "     return((y-y_hat)**2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Create dataset\n",
    "Now we'll create our data that decribe the equation $y=2x+0.5$.\n",
    "We will create only 10 samples but you can do more if you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "torch.Size([10, 1])\n",
      "tensor([[ 2.5000],\n",
      "        [ 4.5000],\n",
      "        [ 6.5000],\n",
      "        [ 8.5000],\n",
      "        [10.5000],\n",
      "        [12.5000],\n",
      "        [14.5000],\n",
      "        [16.5000],\n",
      "        [18.5000],\n",
      "        [20.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.range(1,10).float().unsqueeze(-1)\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "targets = 2. * inputs + 0.5 * torch.ones(10,1)\n",
    "print(targets.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's predict $\\hat{y}$ with the untrained model and see what the output and loss values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5161],\n",
      "        [ 0.0523],\n",
      "        [ 0.6208],\n",
      "        [ 1.1892],\n",
      "        [ 1.7576],\n",
      "        [ 2.3261],\n",
      "        [ 2.8945],\n",
      "        [ 3.4629],\n",
      "        [ 4.0314],\n",
      "        [ 4.5998]], grad_fn=<AddBackward0>)\n",
      "tensor(106.3641, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now if we do one backpropagation step, the gradients of the two parameters $a$ and $b$ we will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5684]], requires_grad=True)\n",
      "tensor([[-127.6605]])\n",
      "tensor([-1.0845], requires_grad=True)\n",
      "tensor([-18.9163])\n",
      "tensor([[0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(a)\n",
    "print(a.grad)\n",
    "\n",
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "245_6rwPaR-T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's time train the model now for 100 iterations and test again the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGn0aA7SaR-U",
    "outputId": "947c5d8b-d48f-4ad5-a2fd-63f23e879e2c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Done\n",
      "a = tensor([[2.1856]], requires_grad=True) b = tensor([-0.7955], requires_grad=True)\n",
      "Predictions tensor([[ 1.3901],\n",
      "        [ 3.5757],\n",
      "        [ 5.7614],\n",
      "        [ 7.9470],\n",
      "        [10.1326],\n",
      "        [12.3182],\n",
      "        [14.5039],\n",
      "        [16.6895],\n",
      "        [18.8751],\n",
      "        [21.0607]], grad_fn=<AddBackward0>)\n",
      "Loss = 0.3596566319465637\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "lr = 1e-3\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        a.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print('Optimization Done')\n",
    "print(f'a = {a} b = {b}')\n",
    "\n",
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(f'Predictions {preds}')\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(f'Loss = {loss.item()}')\n",
    "\n",
    "preds = model(inputs)\n",
    "import matplotlib.pyplot as pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let`s plot our the predictions of the model ($\\hat_{y}$) and observe if they are close to our targets ($y$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_pred = pyplot.plot(inputs.numpy(),preds.detach().numpy(),'r',label = 'Predicted')\n",
    "line_target = pyplot.plot(inputs.numpy(),targets.detach().numpy(),'b',label = 'y=2x+0.5')\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.xlabel('X')\n",
    "pyplot.ylabel('Y')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ly44eqE8aR-a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run linear regression with multidimensional data\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\left[ \\begin{array}{cc}\n",
    "x_{11} & x_{12} &x_{13} \\\\\n",
    "x_{21} & x_{22} &x_{23} \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "x_{N1} & x_{N2} &x_{N3}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\times\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "Wine Quality dataset\n",
    "\n",
    "We will try to solve a real problem now instead of using random data. We will use the linear regression model to\n",
    "predict the wine quality based on different metrichs (pH, acidity, etc.)\n",
    "You can download the dataset from the following link,\n",
    "![Dataset link](https://archive.ics.uci.edu/ml/datasets/Wine+Quality),\n",
    "Let's read our dataset now and explore what type of data it contains.\n",
    "\n",
    "![wine_data](./figures/1.7.data_viz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiMyQgm8aR-c",
    "outputId": "969a16a7-bfe4-475b-9c06-6b5677f648b1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7fae95337b38>\n",
      "torch.Size([1599, 11])\n",
      "torch.Size([1599, 1])\n",
      "tensor([[ -8.8427],\n",
      "        [-12.6074],\n",
      "        [ -8.7062],\n",
      "        ...,\n",
      "        [-17.3114],\n",
      "        [-17.4414],\n",
      "        [-10.6283]], grad_fn=<AddBackward0>)\n",
      "tensor(319.4118, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.3986,  0.4033,  0.8380, -0.7193, -0.4033, -0.5966,  0.1820, -0.8567,\n",
      "          1.1006, -1.0712,  0.1227]], requires_grad=True)\n",
      "tensor([[ -289.8224,   -17.3111,    -9.7031,   -89.3588,    -2.9629,  -579.3581,\n",
      "         -1439.5339,   -33.7111,  -111.6210,   -22.5599,  -354.4185]])\n",
      "tensor([-0.5663], requires_grad=True)\n",
      "tensor([-33.8159])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_wine_data():\n",
    "    with open('./data/winequality-red.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        print(csv_reader)\n",
    "        line_count = 0\n",
    "        wine_data = []\n",
    "        categories = []\n",
    "        for idx,row in enumerate(csv_reader):\n",
    "            #print(row)\n",
    "            if idx ==0 :\n",
    "                categories = row\n",
    "            else:\n",
    "                r = list(map(float, row))\n",
    "                wine_data.append(r)\n",
    "        # Convert inputs and targets to tensors\n",
    "        data_tensor = torch.tensor(wine_data)\n",
    "    return data_tensor,categories\n",
    "\n",
    "\n",
    "a = torch.randn(1, 11, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "data_tensor,categories = read_wine_data()\n",
    "inputs = data_tensor[:,:-1]\n",
    "targets = data_tensor[:,-1].unsqueeze(-1)\n",
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ a.t() + b\n",
    "\n",
    "# MSE loss\n",
    "\n",
    "def mse(y,y_hat):\n",
    "     return((y-y_hat)**2).mean()\n",
    "\n",
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)\n",
    "\n",
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Gradients for weights\n",
    "print(a)\n",
    "print(a.grad)\n",
    "\n",
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmzTOIWhaR-i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's train again our linear regression model using the wine dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2iPT4vZaR-j",
    "outputId": "d49ad10f-b8be-4759-c5e2-887c9c9cd480",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 8.64\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "lr = 1e-4\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        a.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print(f'Loss {loss.item():.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Linear Regression model using PyTorch built in Functions\n",
    "\n",
    "Now, we are going to reimplement the same model using PyTorch built-in libraries.\n",
    "To create a linear model we will use Linear() class from torch.nn package.\n",
    "To calculate MSE loss we will import nn.MSELoss() and torch.optim.SGD to\n",
    "create a stochastic gradient descent optimizer to our model.\n",
    "These are the main steps to do\n",
    "- Read Data\n",
    "- Create Dataloader\n",
    "- Create Model, Optimizer and Loss Functions\n",
    "- Train the model\n",
    "- Test the model\n",
    "\n",
    "Let's train again our classifier to predict the linear relationship $y=2x+0.5$\n",
    "and then we are going to classify again the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.14781543612480164\n",
      "tensor([[1.8806]])\n",
      "tensor([1.2102])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.arange(0,10).float().unsqueeze(-1)\n",
    "\n",
    "targets = 2. * torch.arange(0,10).float().unsqueeze(-1) + 0.5*torch.ones(10,1)\n",
    "\n",
    "lr_model = nn.Linear(in_features=1,out_features=1)\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss(size_average=True)\n",
    "\n",
    "for i in range(100):\n",
    "    preds = lr_model(inputs)\n",
    "    loss = criterion(preds,targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "print(f'Loss {loss.item()}')\n",
    "print(lr_model.weight.data)\n",
    "print(lr_model.bias.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxnEmMqOaR_H",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's classify again our wine dataset now with the PyTorch buit-in functions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PxuI4NSaR_I",
    "outputId": "00393919-4b01-4832-9e6b-d768da60fe4e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7fae95313978>\n",
      "torch.Size([1599, 12])\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "tensor([[5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        ...,\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.]])\n",
      "torch.Size([1599, 11])\n",
      "torch.Size([1599, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_tensor,categories = read_wine_data()\n",
    "#results = list(map(int, results))\n",
    "print(data_tensor.shape)\n",
    "print(categories)\n",
    "inputs = data_tensor[:,:-1]\n",
    "targets = data_tensor[:,-1].unsqueeze(-1)\n",
    "print(targets)\n",
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "#results = list(map(int, results))\n",
    "\n",
    "lr_model = nn.Linear(in_features=11,out_features=1)\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.0001)\n",
    "criterion = nn.MSELoss(size_average=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we'll create an iterable dataset in order to train our model. We'll use `TensorDataset` and  `DataLoader`\n",
    "from PyTorch. `TensorDataset` takes inputs and targets tensors as arguments and wraps them together. Then `Dataloader`\n",
    "combines a dataset and a sampler,  provides an iterable over the given dataset and generates batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "# Define data loader\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "#next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are ready to train our model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    average_loss = 0.0\n",
    "    for batch_index, (x,y) in enumerate(train_dl):\n",
    "        preds = lr_model(x)\n",
    "        loss = criterion(preds,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        average_loss +=loss.item()\n",
    "    print(f'Epoch {i} Average_loss {average_loss/len(train_dl):.2f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Average_loss 42.85\n",
      "Epoch 1 Average_loss 6.92\n",
      "Epoch 2 Average_loss 4.20\n",
      "Epoch 3 Average_loss 2.73\n",
      "Epoch 4 Average_loss 1.89\n",
      "Epoch 5 Average_loss 1.40\n",
      "Epoch 6 Average_loss 1.13\n",
      "Epoch 7 Average_loss 0.97\n",
      "Epoch 8 Average_loss 0.88\n",
      "Epoch 9 Average_loss 0.82\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    average_loss = 0.0\n",
    "    for batch_index, (x,y) in enumerate(train_dl):\n",
    "        preds = lr_model(x)\n",
    "        loss = criterion(preds,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        average_loss +=loss.item()\n",
    "    print(f'Epoch {i} Average_loss {average_loss/len(train_dl):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.7.linear_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}