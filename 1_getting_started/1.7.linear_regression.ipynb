{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z6sEB4YaR9-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "<!-- useful links\n",
        "![Linear_regression_img](https://github.com/iliasprc/pytorch-tutorials/blob/master/1_getting_started/figures/1.7.linear_regression.png)\n",
        "\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=zPG4NjIkCjc\n",
        "\n",
        "https://www.kaggle.com/aakashns/pytorch-basics-linear-regression-from-scratch -->\n",
        "\n",
        "Regression analysis is a statistical tool  for determining the connection of two or more variables.\n",
        "\n",
        "Linear Regression models a linear relationship between two variables. \n",
        "\n",
        "\n",
        "In more detail, the regression is referred to as Simple Linear Regression, when there is just one input variable. To describe a linear connection with the   dependent   variable  $y$, we employ a single independent variable $x$.\n",
        "Linear Regression is represented by the  equation  $y=ax+b$ and aims to find the optimal values of $a$ and $b$ that best describe the relationship of the variables. More specifically, this equation describes a straight\n",
        "line with slope equal to $a$, while $b$ the intercept (the value of $y$ when $x = 0$). \n",
        "\n",
        "If there is more than predicting variable, the regression is referred to as Multiple Linear Regression.\n",
        "\n",
        "Now, let's create and initialize randomly our linear regression model's variables  $a$ and $b$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bn6a7tTaR9w",
        "outputId": "75fc6a6d-9f29-41ca-bb79-7d86cdcb7a78",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f51c4743510>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgQ5q7oTaR9_",
        "outputId": "96e66ca2-d2a0-49ac-9946-8f984b3ed9ac",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5410], requires_grad=True)\n",
            "tensor([-0.2934], requires_grad=True)\n",
            "tensor([-3.6509], grad_fn=<AddBackward0>) tensor([-2.1788])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "a = torch.randn(1,requires_grad=True)\n",
        "b = torch.randn(1,requires_grad=True)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "x = torch.randn(1)\n",
        "y = a*x+b\n",
        "\n",
        "y.backward()\n",
        "print(y,x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKMOmY6EaR-J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Fitting a simple line\n",
        "\n",
        "Let's create a simple dataset and try to fit our linear regression model. We'll initialize randomly our $a$ and $b$ and try to run\n",
        "some iterations to find the optimal weights that fit our following line.\n",
        "\n",
        "$y=2x+0.5$\n",
        "\n",
        "The following code block creates  the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zJRBkGbRaR-L",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "a = torch.randn((1,1),requires_grad=True)\n",
        "b = torch.randn(1,requires_grad=True)\n",
        "\n",
        "def model(x):\n",
        "    return x @ a.t() + b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Least-Squares Regression\n",
        "The least-squares approach is the most frequent method for fitting a regression line.\n",
        "By reducing the sum of the squares of the vertical deviations from each data point to the line, this approach determines the best-fitting line for the observed data (if a point lies on the fitted line exactly, then its vertical deviation is 0).\n",
        "There are no cancellations between positive and negative numbers since the deviations are squared first and then summed. "
      ],
      "metadata": {
        "id": "YcM35-lMuKbq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "axJi62mPzMvl"
      },
      "source": [
        "### MSE LOSS\n",
        "Mean Squared Error (MSE) or mean squared deviation (MSD) of an estimator\n",
        "(of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors.\n",
        "\n",
        "$MSE(y,\\hat {y}) =\\sum_{i=1}^{N} (y_{i}-\\hat{y}_{i})^{2} $\n",
        "\n",
        "In other words MSE is the mean ${ \\left({\\frac {1}{n}}\\sum _{i=1}^{n}\\right)}$\n",
        "of the squares of the errors ${ (y_{i}-{\\hat {y_{i}}})^{2}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8J_jhNAxzMvm"
      },
      "outputs": [],
      "source": [
        "def mse(y,y_hat):\n",
        "     return((y-y_hat)**2).mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "h_47Wur8zMvm"
      },
      "source": [
        "\n",
        "### Create dataset\n",
        "Now we'll create our data that decribe the equation $y=2x+0.5$.\n",
        "We will create only 10 samples but you can do more if you like by changing the variable $N$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vykq5d2MzMvn",
        "outputId": "318d2130-088c-44c7-f437-b58b1d989abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1])\n",
            "tensor([[ 1.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.],\n",
            "        [ 5.],\n",
            "        [ 6.],\n",
            "        [ 7.],\n",
            "        [ 8.],\n",
            "        [ 9.],\n",
            "        [10.]])\n",
            "torch.Size([10, 1])\n",
            "tensor([[ 2.5000],\n",
            "        [ 4.5000],\n",
            "        [ 6.5000],\n",
            "        [ 8.5000],\n",
            "        [10.5000],\n",
            "        [12.5000],\n",
            "        [14.5000],\n",
            "        [16.5000],\n",
            "        [18.5000],\n",
            "        [20.5000]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "N=10\n",
        "inputs = torch.range(1,N).float().unsqueeze(-1)\n",
        "print(inputs.shape)\n",
        "print(inputs)\n",
        "targets = 2. * inputs + 0.5 * torch.ones(N,1)\n",
        "print(targets.shape)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mWfNOOkVzMvo"
      },
      "source": [
        "Let's predict $\\hat{y}$ with the untrained model and see what the output and loss values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-xtKVyNzMvp",
        "outputId": "bca860a9-0d66-4262-e3db-15b478baa9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5161],\n",
            "        [ 0.0523],\n",
            "        [ 0.6208],\n",
            "        [ 1.1892],\n",
            "        [ 1.7576],\n",
            "        [ 2.3261],\n",
            "        [ 2.8945],\n",
            "        [ 3.4629],\n",
            "        [ 4.0314],\n",
            "        [ 4.5998]], grad_fn=<AddBackward0>)\n",
            "tensor(106.3641, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)\n",
        "\n",
        "# Compute gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UDtWnOUtzMvq"
      },
      "source": [
        "Now if we do one backpropagation step, the gradients of the two parameters $a$ and $b$ we will be calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96stz8gczMvq",
        "outputId": "a27f56d1-d420-4233-edf0-cee26fe79c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5684]], requires_grad=True)\n",
            "tensor([[-127.6605]])\n",
            "tensor([-1.0845], requires_grad=True)\n",
            "tensor([-18.9163])\n",
            "tensor([[0.]])\n",
            "tensor([0.])\n"
          ]
        }
      ],
      "source": [
        "# Gradients for weights\n",
        "print(a)\n",
        "print(a.grad)\n",
        "\n",
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)\n",
        "\n",
        "a.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "245_6rwPaR-T",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "It's time train the model now for 100 iterations and test again the predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGn0aA7SaR-U",
        "outputId": "ed063cee-2dd2-476b-e418-37e8a2544470",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization Done\n",
            "a = tensor([[2.1856]], requires_grad=True) b = tensor([-0.7955], requires_grad=True)\n",
            "Predictions tensor([[ 1.3901],\n",
            "        [ 3.5757],\n",
            "        [ 5.7614],\n",
            "        [ 7.9470],\n",
            "        [10.1326],\n",
            "        [12.3182],\n",
            "        [14.5039],\n",
            "        [16.6895],\n",
            "        [18.8751],\n",
            "        [21.0607]], grad_fn=<AddBackward0>)\n",
            "Loss = 0.3596566319465637\n"
          ]
        }
      ],
      "source": [
        "# Train for 100 epochs\n",
        "lr = 1e-3\n",
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        a -= a.grad * lr\n",
        "        b -= b.grad * lr\n",
        "        a.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "print('Optimization Done')\n",
        "print(f'a = {a} b = {b}')\n",
        "\n",
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(f'Predictions {preds}')\n",
        "\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(f'Loss = {loss.item()}')\n",
        "\n",
        "preds = model(inputs)\n",
        "import matplotlib.pyplot as pyplot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b-5FsuOrzMvr"
      },
      "source": [
        "Now let`s plot our the predictions of the model ($\\hat{y}$) and observe if they are close to our targets ($y$).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "KPCPS1cKzMvr",
        "outputId": "288840c0-fb1c-465c-c6db-f95236ad6455"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "line_pred = pyplot.plot(inputs.numpy(),preds.detach().numpy(),'r',label = 'Predicted')\n",
        "line_target = pyplot.plot(inputs.numpy(),targets.detach().numpy(),'b',label = 'y=2x+0.5')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "pyplot.xlabel('X')\n",
        "pyplot.ylabel('Y')\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression"
      ],
      "metadata": {
        "id": "VATeEqqs3X0Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly44eqE8aR-a",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Run Linear Regression with multidimensional data\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "y =\n",
        "\\left[ \\begin{array}{cc}\n",
        "x_{11} & x_{12} &x_{13} \\\\\n",
        "x_{21} & x_{22} &x_{23} \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "x_{N1} & x_{N2} &x_{N3}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$\n",
        "\n",
        "Wine Quality dataset\n",
        "\n",
        "Now, we will try to solve a real problem  instead of using random data. We will use the linear regression model to\n",
        "predict the wine quality based on different metrics (pH, acidity, etc.)\n",
        "You can download the dataset from the following link,\n",
        "![Dataset link](https://archive.ics.uci.edu/ml/datasets/Wine+Quality),\n",
        "\n",
        "Let's read our dataset now and explore what type of data it contains.\n",
        "\n",
        "![wine_data](https://github.com/iliasprc/pytorch-tutorials/blob/master/1_getting_started/figures/1.7.data_viz.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiMyQgm8aR-c",
        "outputId": "92bc5f48-344b-44fb-e334-4fb49015d6ec",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1599, 11])\n",
            "torch.Size([1599, 1])\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "def read_wine_data():\n",
        "    with open('winequality-red.csv') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
        "        \n",
        "        line_count = 0\n",
        "        wine_data = []\n",
        "        categories = []\n",
        "        for idx,row in enumerate(csv_reader):\n",
        "            #print(row)\n",
        "            if idx ==0 :\n",
        "                categories = row\n",
        "            else:\n",
        "                r = list(map(float, row))\n",
        "                wine_data.append(r)\n",
        "        # Convert inputs and targets to tensors\n",
        "        data_tensor = torch.tensor(wine_data)\n",
        "    return data_tensor,categories\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_tensor,categories = read_wine_data()\n",
        "inputs = data_tensor[:,:-1]\n",
        "targets = data_tensor[:,-1].unsqueeze(-1)\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will cosntruct our linear regression model using `model()` function and the MSE loss `mse()`for the optimization using the least squares method."
      ],
      "metadata": {
        "id": "sgNxtBppxTo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = torch.randn(1, 11, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "# Define the model\n",
        "def model(x):\n",
        "    return x @ a.t() + b\n",
        "\n",
        "# MSE loss\n",
        "\n",
        "def mse(y,y_hat):\n",
        "     return((y-y_hat)**2).mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "4aQR25xVxVKY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's fit the whole dataset once to and observe the loss value and the gradients."
      ],
      "metadata": {
        "id": "g3HRT8URxznp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss.item())\n",
        "\n",
        "# Compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# Gradients for weights\n",
        "print(a)\n",
        "print(a.grad)\n",
        "\n",
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)\n",
        "\n",
        "a.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46B_yCfYxz1z",
        "outputId": "23cd5787-d0dd-48dc-d222-acc2b4f99dbf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[32.2434],\n",
            "        [36.3522],\n",
            "        [39.5605],\n",
            "        ...,\n",
            "        [24.7045],\n",
            "        [19.7853],\n",
            "        [40.5215]], grad_fn=<AddBackward0>)\n",
            "1197.431884765625\n",
            "tensor([[-0.3629,  0.4028,  1.0718,  3.1510, -0.3178, -0.9579,  0.4065,  0.4106,\n",
            "         -1.8387,  0.8823,  3.2554]], requires_grad=True)\n",
            "tensor([[ 543.6219,   34.7763,   18.4397,  181.1810,    5.7427, 1029.6223,\n",
            "         3506.3984,   65.1608,  216.0801,   43.1362,  683.9539]])\n",
            "tensor([0.3486], requires_grad=True)\n",
            "tensor([65.3699])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmzTOIWhaR-i",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Let's train again our linear regression model using the wine dataset now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2iPT4vZaR-j",
        "outputId": "7ff28468-2b7e-4405-d332-1c5183765299",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 54.39\n"
          ]
        }
      ],
      "source": [
        "# Train for 100 epochs\n",
        "lr = 1e-4\n",
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    # Calculate gradients\n",
        "    loss.backward()\n",
        "    # Adjust weights & reset gradients\n",
        "    with torch.no_grad():\n",
        "        a -= a.grad * lr\n",
        "        b -= b.grad * lr\n",
        "        a.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "print(f'Loss {loss.item():.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyhmqHt5zMvt"
      },
      "source": [
        "### Define Linear Regression model using PyTorch built in Functions\n",
        "\n",
        "Now, we are going to reimplement the same model using PyTorch built-in libraries.\n",
        "To create a linear model we will use `Linear()` class from `torch.nn` package.\n",
        "To calculate MSE loss we will import `nn.MSELoss()` and `torch.optim.SGD` to\n",
        "create a stochastic gradient descent optimizer to train our model.\n",
        "These are the main steps to do\n",
        "- Read Data\n",
        "- Create Dataloader\n",
        "- Create Model, Optimizer and Loss Functions\n",
        "- Train the model\n",
        "- Test the model\n",
        "\n",
        "Let's train again our classifier to predict the linear relationship $y=2x+0.5$\n",
        "and then we are going to classify again the wine dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y2KscwwzMvu",
        "outputId": "a455f83a-41fb-48bb-fcf4-3500a13a2416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 0.0020583984442055225\n",
            "a =  tensor([[1.9849]])\n",
            "b =  tensor([0.5606])\n"
          ]
        }
      ],
      "source": [
        "inputs = torch.arange(0,10).float().unsqueeze(-1)\n",
        "\n",
        "targets = 2. * torch.arange(0,10).float().unsqueeze(-1) + 0.5*torch.ones(10,1)\n",
        "\n",
        "lr_model = nn.Linear(in_features=1,out_features=1)\n",
        "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i in range(100):\n",
        "    preds = lr_model(inputs)\n",
        "    loss = criterion(preds,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "print(f'Loss {loss.item()}')\n",
        "print('a = ' ,lr_model.weight.data)\n",
        "print('b = ',lr_model.bias.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxnEmMqOaR_H",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now, let's classify again our wine dataset now using the PyTorch built-in functions now from `torch.nn` package. We will create a linear regression model using `nn.Linear()` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PxuI4NSaR_I",
        "outputId": "3efa0c89-e12f-45da-bf91-5e53187ada6c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_csv.reader object at 0x7f51c328b5d0>\n",
            "torch.Size([1599, 12])\n",
            "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
            "Initialize weights for the linear model \n",
            "w =  Parameter containing:\n",
            "tensor([[-0.2748, -0.0190,  0.1894,  0.0783,  0.0953,  0.0280,  0.1124, -0.0735,\n",
            "         -0.1199, -0.2818, -0.2271]], requires_grad=True)\n",
            "b =  Parameter containing:\n",
            "tensor([0.1307], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_tensor,categories = read_wine_data()\n",
        "#results = list(map(int, results))\n",
        "print(data_tensor.shape)\n",
        "print(categories)\n",
        "inputs = data_tensor[:,:-1]\n",
        "targets = data_tensor[:,-1].unsqueeze(-1)\n",
        " \n",
        "#results = list(map(int, results))\n",
        "\n",
        "lr_model = nn.Linear(in_features=11,out_features=1)\n",
        "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.0001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print('Initialize weights for the linear model ')\n",
        "print('w = ', lr_model.weight)\n",
        "\n",
        "print('b = ',lr_model.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_Pl53877zMvv"
      },
      "source": [
        "Now, we'll create an iterable dataset in order to train our model. We'll use `TensorDataset` and  `DataLoader`\n",
        "from PyTorch. `TensorDataset` takes inputs and targets tensors as arguments and wraps them together. Then, the `Dataloader`\n",
        "combines a dataset and a sampler and  provides an iterable over the given dataset in order to generate batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_zEUidzMvw",
        "outputId": "08583f6a-5fea-4dfd-a03b-f1c77ca903fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[1.0200e+01, 4.4000e-01, 5.8000e-01, 4.1000e+00, 9.2000e-02, 1.1000e+01,\n",
              "          2.4000e+01, 9.9745e-01, 3.2900e+00, 9.9000e-01, 1.2000e+01],\n",
              "         [6.6000e+00, 6.1000e-01, 1.0000e-02, 1.9000e+00, 8.0000e-02, 8.0000e+00,\n",
              "          2.5000e+01, 9.9746e-01, 3.6900e+00, 7.3000e-01, 1.0500e+01],\n",
              "         [9.9000e+00, 5.3000e-01, 5.7000e-01, 2.4000e+00, 9.3000e-02, 3.0000e+01,\n",
              "          5.2000e+01, 9.9710e-01, 3.1900e+00, 7.6000e-01, 1.1600e+01],\n",
              "         [1.0400e+01, 4.3000e-01, 5.0000e-01, 2.3000e+00, 6.8000e-02, 1.3000e+01,\n",
              "          1.9000e+01, 9.9600e-01, 3.1000e+00, 8.7000e-01, 1.1400e+01],\n",
              "         [9.9000e+00, 3.5000e-01, 4.1000e-01, 2.3000e+00, 8.3000e-02, 1.1000e+01,\n",
              "          6.1000e+01, 9.9820e-01, 3.2100e+00, 5.0000e-01, 9.5000e+00],\n",
              "         [5.0000e+00, 3.8000e-01, 1.0000e-02, 1.6000e+00, 4.8000e-02, 2.6000e+01,\n",
              "          6.0000e+01, 9.9084e-01, 3.7000e+00, 7.5000e-01, 1.4000e+01],\n",
              "         [7.9000e+00, 8.8500e-01, 3.0000e-02, 1.8000e+00, 5.8000e-02, 4.0000e+00,\n",
              "          8.0000e+00, 9.9720e-01, 3.3600e+00, 3.3000e-01, 9.1000e+00],\n",
              "         [7.2000e+00, 3.8000e-01, 3.8000e-01, 2.8000e+00, 6.8000e-02, 2.3000e+01,\n",
              "          4.2000e+01, 9.9356e-01, 3.3400e+00, 7.2000e-01, 1.2900e+01],\n",
              "         [8.4000e+00, 3.4000e-01, 4.2000e-01, 2.1000e+00, 7.2000e-02, 2.3000e+01,\n",
              "          3.6000e+01, 9.9392e-01, 3.1100e+00, 7.8000e-01, 1.2400e+01],\n",
              "         [7.2000e+00, 7.3000e-01, 2.0000e-02, 2.5000e+00, 7.6000e-02, 1.6000e+01,\n",
              "          4.2000e+01, 9.9720e-01, 3.4400e+00, 5.2000e-01, 9.3000e+00]]),\n",
              " tensor([[7.],\n",
              "         [5.],\n",
              "         [7.],\n",
              "         [6.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [4.],\n",
              "         [7.],\n",
              "         [6.],\n",
              "         [5.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "# Define data loader\n",
        "batch_size = 10\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train our model.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "HrU0ykCmzMvw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Average_loss 10.35\n",
            "Epoch 1 Average_loss 0.94\n",
            "Epoch 2 Average_loss 0.65\n",
            "Epoch 3 Average_loss 0.62\n",
            "Epoch 4 Average_loss 0.60\n",
            "Epoch 5 Average_loss 0.59\n",
            "Epoch 6 Average_loss 0.59\n",
            "Epoch 7 Average_loss 0.58\n",
            "Epoch 8 Average_loss 0.57\n",
            "Epoch 9 Average_loss 0.56\n",
            "Epoch 10 Average_loss 0.56\n",
            "Epoch 11 Average_loss 0.56\n",
            "Epoch 12 Average_loss 0.54\n",
            "Epoch 13 Average_loss 0.55\n",
            "Epoch 14 Average_loss 0.55\n",
            "Epoch 15 Average_loss 0.56\n",
            "Epoch 16 Average_loss 0.54\n",
            "Epoch 17 Average_loss 0.54\n",
            "Epoch 18 Average_loss 0.55\n",
            "Epoch 19 Average_loss 0.53\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "    average_loss = 0.0\n",
        "    for batch_index, (x,y) in enumerate(train_dl):\n",
        "        preds = lr_model(x)\n",
        "        loss = criterion(preds,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        average_loss +=loss.item()\n",
        "    print(f'Epoch {i} Average_loss {average_loss/len(train_dl):.2f}')\n",
        "    \n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLprfS-fzMvw",
        "outputId": "8eca3fa1-0355-4ac3-b227-1dab8a754ecb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Learned parameters of the linear regression model')\n",
        "print('w = ', lr_model.weight)\n",
        "print('b = ',lr_model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0npruz8iwSGo",
        "outputId": "13d88e88-a0ce-40bc-92f3-8791823c62e3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned parameters of the linear regression model\n",
            "w =  Parameter containing:\n",
            "tensor([[ 0.1091, -0.0068,  0.2012,  0.0485,  0.0993,  0.0092, -0.0007, -0.0137,\n",
            "          0.0814, -0.2258,  0.4060]], requires_grad=True)\n",
            "b =  Parameter containing:\n",
            "tensor([0.1908], requires_grad=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "1.7.linear_regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}