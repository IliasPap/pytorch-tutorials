{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "1.7.linear_regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCbwGz4ElBGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "torch.__version__\n",
        "torch.manual_seed(0)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyZ7XEgpyLtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "6f8444d2-dc1f-40cc-fa5c-63b11cceeb43"
      },
      "source": [
        "# x = 2.*torch.abs(torch.randn(100)).numpy()\n",
        "# y = 2.*torch.abs(torch.randn(100)).numpy()\n",
        "# z = torch.range(0,5)\n",
        "# plt.title('Linear Regression')\n",
        "# plt.xlabel('x')\n",
        "# plt.ylabel('y')\n",
        "# plt.plot(z,'r')\n",
        "# plt.plot(x, y, 'bo')\n",
        "# plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9VC2aJ5wlBGx",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "useful links\n",
        "\n",
        "https://www.youtube.com/watch?v=zPG4NjIkCjc\n",
        "\n",
        "https://www.kaggle.com/aakashns/pytorch-basics-linear-regression-from-scratch\n",
        "\n",
        "Linear regression models a linear relationship between two variables. There is usually an independent value $x$\n",
        "and a dependent value $y$. Linear regression has an equation with the form $y=ax+b$ and finds the optimal values\n",
        "$a$ and $b$ that best describe the relationship of the variables. More specifically, this equation describes a straight\n",
        "line with slope eaual to $a$ and $b$ the intercept (the value of $y$ when $x = 0$).\n",
        "\n",
        "\n",
        "\n",
        "Let's create and initialize randomly our model's variables  $a$ and $b$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j__oPpUvlBGy",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf06fff2-571e-49ca-fb15-24830e963187"
      },
      "source": [
        "\n",
        "a = torch.randn(1,requires_grad=True)\n",
        "b = torch.randn(1,requires_grad=True)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "x = torch.randn(1)\n",
        "y = a*x+b\n",
        "\n",
        "y.backward()\n",
        "print(y,x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.5410], requires_grad=True)\n",
            "tensor([-0.2934], requires_grad=True)\n",
            "tensor([-3.6509], grad_fn=<AddBackward0>) tensor([-2.1788])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NK_rYxmUlBG3",
        "colab_type": "text"
      },
      "source": [
        "## Fit simple line\n",
        "\n",
        "Let's create dummy data and try to fit our linear regression model. We'll initialize randomly our a,b and try to run\n",
        "some iterations to find the optimal weights that fi oour following line.\n",
        "\n",
        "$y=2x+0.5$\n",
        "\n",
        "Now let's create our data and  fit our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NpiaA-oOlBG4",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2a1610e-653e-43f5-d3b6-cf60255f66c8"
      },
      "source": [
        "\n",
        "a = torch.randn((1,1),requires_grad=True)\n",
        "b = torch.randn(1,requires_grad=True)\n",
        "\n",
        "def model(x):\n",
        "    return x @ a.t() + b\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1])\n",
            "tensor([[ 1.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.],\n",
            "        [ 5.],\n",
            "        [ 6.],\n",
            "        [ 7.],\n",
            "        [ 8.],\n",
            "        [ 9.],\n",
            "        [10.]])\n",
            "torch.Size([10, 1])\n",
            "tensor([[ 2.5000],\n",
            "        [ 4.5000],\n",
            "        [ 6.5000],\n",
            "        [ 8.5000],\n",
            "        [10.5000],\n",
            "        [12.5000],\n",
            "        [14.5000],\n",
            "        [16.5000],\n",
            "        [18.5000],\n",
            "        [20.5000]])\n",
            "tensor([[-0.5161],\n",
            "        [ 0.0523],\n",
            "        [ 0.6208],\n",
            "        [ 1.1892],\n",
            "        [ 1.7576],\n",
            "        [ 2.3261],\n",
            "        [ 2.8945],\n",
            "        [ 3.4629],\n",
            "        [ 4.0314],\n",
            "        [ 4.5998]], grad_fn=<AddBackward0>)\n",
            "tensor(106.3641, grad_fn=<MeanBackward0>)\n",
            "tensor([[0.5684]], requires_grad=True)\n",
            "tensor([[-127.6605]])\n",
            "tensor([-1.0845], requires_grad=True)\n",
            "tensor([-18.9163])\n",
            "tensor([[0.]])\n",
            "tensor([0.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKf1HKtC8SqU",
        "colab_type": "text"
      },
      "source": [
        "# MSE LOSS\n",
        " Mean Squared Error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors.\n",
        "\n",
        "$MSE(y,y^{'}) =\\sum_{i=1}^{N} (y_{i}-y^{'}_{i})^{2} $\n",
        "\n",
        "\n",
        "In other words MSE is the mean ${\\displaystyle \\left({\\frac {1}{n}}\\sum _{i=1}^{n}\\right)}$ of the squares of the errors ${\\displaystyle (y_{i}-{\\hat {y_{i}}})^{2}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ghNsVY8UMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def mse(y,y_hat):\n",
        "     return((y-y_hat)**2).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLXxb7NU8a3P",
        "colab_type": "text"
      },
      "source": [
        "# Create dataset\n",
        "Now we'll create our data that decribe the equation $y=2x+0.5$.\n",
        "We will create only 10 samples but you can do more if you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxzPq1cv8bJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = 10\n",
        "inputs = torch.range(1,samples).float().unsqueeze(-1)\n",
        "print(inputs.shape)\n",
        "print(inputs)\n",
        "targets = 2. * inputs + 0.5*torch.ones(samples,1)\n",
        "print(targets.shape)\n",
        "print(targets)\n",
        "\n",
        "\n",
        "a.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKvnLrjc8f5H",
        "colab_type": "text"
      },
      "source": [
        "Predict $y^{'}$ with the untrained model and see the output and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXbEx50w8gKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)\n",
        "\n",
        "# Compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# Gradients for weights\n",
        "print(a)\n",
        "print(a.grad)\n",
        "\n",
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0aWAa2iIlBG9",
        "colab_type": "text"
      },
      "source": [
        "Let's train the model for 100 iterations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fI0M0kVXlBG-",
        "colab_type": "code",
        "colab": {},
        "outputId": "386c6cd6-bdf9-44d2-9262-6b6a70b56148"
      },
      "source": [
        "\n",
        "# Train for 100 epochs\n",
        "lr = 1e-3\n",
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    \n",
        "    loss = mse(preds, targets)\n",
        "    \n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        a -= a.grad * lr\n",
        "        b -= b.grad * lr\n",
        "        a.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "print('Optimization Done')\n",
        "print(f'a = {a} b = {b}')\n",
        "\n",
        "\n",
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(f'Predictions {preds}')\n",
        "\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(f'Loss = {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization Done\n",
            "a = tensor([[2.1856]], requires_grad=True) b = tensor([-0.7955], requires_grad=True)\n",
            "Predictions tensor([[ 1.3901],\n",
            "        [ 3.5757],\n",
            "        [ 5.7614],\n",
            "        [ 7.9470],\n",
            "        [10.1326],\n",
            "        [12.3182],\n",
            "        [14.5039],\n",
            "        [16.6895],\n",
            "        [18.8751],\n",
            "        [21.0607]], grad_fn=<AddBackward0>)\n",
            "Loss = 0.3596566319465637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2O6AsxFAlBHD",
        "colab_type": "text"
      },
      "source": [
        "## Run linear regression with multidimensional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9sd75wAlBHD",
        "colab_type": "code",
        "colab": {},
        "outputId": "caae8492-2206-4665-f543-904c3689bcbb"
      },
      "source": [
        "# Weights and biases\n",
        "a = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')\n",
        "\n",
        "\n",
        "# # Input (temp, rainfall, humidity)\n",
        "# inputs = 0.001*np.array([[73 ], \n",
        "#                    [91 ], \n",
        "#                    [87], \n",
        "#                    [102], \n",
        "#                    [69]], dtype='float32')\n",
        "\n",
        "# # Targets (apples, oranges)\n",
        "# targets = 0.001*np.array([[56], \n",
        "#                     [81], \n",
        "#                     [119], \n",
        "#                     [22], \n",
        "#                     [103]], dtype='float32')\n",
        "\n",
        "# Convert inputs and targets to tensors\n",
        "\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "def model(x):\n",
        "    return x @ a.t() + b\n",
        "\n",
        "# MSE loss\n",
        "\n",
        "def mse(y,y_hat):\n",
        "     return((y-y_hat)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)\n",
        "\n",
        "# Compute gradients\n",
        "loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "# Gradients for weights\n",
        "print(a)\n",
        "print(a.grad)\n",
        "\n",
        "\n",
        "\n",
        "# Gradients for bias\n",
        "print(b)\n",
        "print(b.grad)\n",
        "\n",
        "\n",
        "\n",
        "a.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(a.grad)\n",
        "print(b.grad)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 3)\n",
            "(5, 2)\n",
            "tensor([[ -38.8561, -106.0418],\n",
            "        [ -37.9619, -139.9880],\n",
            "        [ -18.8418, -152.0850],\n",
            "        [ -94.1238, -113.6402],\n",
            "        [   1.0621, -130.9709]], grad_fn=<AddBackward0>)\n",
            "tensor(32154.3379, grad_fn=<MeanBackward0>)\n",
            "tensor([[-1.3986,  0.4033,  0.8380],\n",
            "        [-0.7193, -0.4033, -0.5966]], requires_grad=True)\n",
            "tensor([[ -9724.1221, -10014.8340,  -6223.8867],\n",
            "        [-18439.3301, -20335.5742, -12519.9219]])\n",
            "tensor([ 0.1820, -0.8567], requires_grad=True)\n",
            "tensor([-113.9443, -220.5452])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ws0QtHwYlBHG",
        "colab_type": "text"
      },
      "source": [
        "Iterate again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0f3t8e9glBHH",
        "colab_type": "code",
        "colab": {},
        "outputId": "db61a537-1955-4796-8f21-17d57363f215"
      },
      "source": [
        "# Train for 100 epochs\n",
        "lr = 1e-5\n",
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    \n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        a -= a.grad * lr\n",
        "        b -= b.grad * lr\n",
        "        a.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "print(f'Loss {loss.item():.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 32154.34\n",
            "Loss 9129929.00\n",
            "Loss 2610502400.00\n",
            "Loss 746420764672.00\n",
            "Loss 213424055255040.00\n",
            "Loss 61024338450579456.00\n",
            "Loss 17448686582851698688.00\n",
            "Loss 4989102303899824422912.00\n",
            "Loss 1426534277232024658903040.00\n",
            "Loss 407888870934643492467507200.00\n",
            "Loss 116627652230322923310191476736.00\n",
            "Loss 33347338636072866334230678863872.00\n",
            "Loss 9535003514718354129369510547816448.00\n",
            "Loss 2726342801076504172003317441493991424.00\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss inf\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8n5CvrWBlBHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Oq5QN3xelBHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e0zHbNSYlBHQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "3a9cf10e-fbff-4113-fbe5-0e5c65bbf8a5"
      },
      "source": [
        "# Train for 100 epochs\n",
        "lr = 1e-3\n",
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    print(f'Loss {loss.item():.2f}')\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        a -= a.grad * lr\n",
        "        b -= b.grad * lr\n",
        "        a.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n",
            "Loss nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5miY4Px3lBHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LODbGO2UlBHX",
        "colab_type": "text"
      },
      "source": [
        "## Define Linear Regression model using PyTorch built-in Functions\n",
        "\n",
        "We will reimplement the same model using PyTorch built-in libraries. To create a linear model we will use `Linear()` class from `torch.nn` package.\n",
        "To calculate MSE loss we will import `nn.MSELoss()` and `torch.optim.SGD` to create a Stochastic Gradient Descent optimizer and train our model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2t0GhzizlBHX",
        "colab_type": "code",
        "colab": {},
        "outputId": "7310809a-bb51-4280-927e-706465487831"
      },
      "source": [
        "\n",
        "inputs = torch.range(1,10).float().unsqueeze(-1)\n",
        "#print(inputs.shape)\n",
        "#print(inputs)\n",
        "targets = 2. * torch.range(1,10).float().unsqueeze(-1) + 0.5*torch.ones(10,1)\n",
        "#print(targets.shape)\n",
        "\n",
        "lr_model = nn.Linear(in_features=1,out_features=1)\n",
        "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.001)\n",
        "criterion = nn.MSELoss(size_average=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  after removing the cwd from sys.path.\n",
            "/home/iliasprc/Documents/penvs/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.026713624596595764\n",
            "tensor([[2.0499]])\n",
            "tensor([0.1472])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5syA45L6w2L",
        "colab_type": "text"
      },
      "source": [
        "As you can see, using built-in functions  is much easier and requires significantly less code.\n",
        "Now let's train the model.\n",
        "The main steps of 1 training iteration are: \n",
        "1. Generate predictions with the linear model\n",
        "1. Calculate loss and backpropagate `loss.backward()`\n",
        "1. Update weights and biases of linear model `optimizer.step()`\n",
        "1. Finally, call `optimizer.zero_grad()` to zero the gradient buffers of the model.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTlFTTLh6xNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        "    preds = lr_model(inputs)\n",
        "    loss = criterion(preds,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVpPAod7zGg",
        "colab_type": "text"
      },
      "source": [
        "Now that we trained our model, let's print the final loss and updated weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQFUurX76YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss.item())\n",
        "print(lr_model.weight.data)\n",
        "print(lr_model.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XaTlJ6XFlBHa",
        "colab_type": "text"
      },
      "source": [
        "# Wine Quality dataset\n",
        "\n",
        "We will tackle to solve a real problem now instead of random data. We will use the linear regression model to predict the wine quality based on different metrichs (pH,acidity etc.)\n",
        "\n",
        "You can download the dataset from the following link\n",
        "![Dataset link]https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
        "\n",
        "- Read Data\n",
        "- Create Dataloader\n",
        "- Model\n",
        "- Train\n",
        "\n",
        "Let's read our dataset now and explore what type of data it contains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TKNs8dbFlBHb",
        "colab_type": "code",
        "colab": {},
        "outputId": "b7b3f1bf-7a9f-4d66-9f7e-440049bc8355"
      },
      "source": [
        "import csv\n",
        "\n",
        "def read_wine_data():\n",
        "    with open('./data/winequality-red.csv') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
        "        print(csv_reader)\n",
        "        line_count = 0\n",
        "        wine_data = []\n",
        "        categories = []\n",
        "        for idx,row in enumerate(csv_reader):\n",
        "            #print(row)\n",
        "            if idx ==0 :\n",
        "                categories = row\n",
        "            else:\n",
        "\n",
        "\n",
        "                r = list(map(float, row))\n",
        "                wine_data.append(r)\n",
        "        data_tensor = torch.tensor(wine_data)\n",
        "    return data_tensor,categories\n",
        "\n",
        "\n",
        "data_tensor,categories = read_wine_data()\n",
        "#results = list(map(int, results))\n",
        "print(data_tensor.shape)\n",
        "print(categories)\n",
        "inputs = data_tensor[:,:-1]\n",
        "targets = data_tensor[:,-1].unsqueeze(-1)\n",
        "print(targets)\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_csv.reader object at 0x7fb2c3ddc6d8>\n",
            "torch.Size([1599, 12])\n",
            "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
            "tensor([[5.],\n",
            "        [5.],\n",
            "        [5.],\n",
            "        ...,\n",
            "        [6.],\n",
            "        [5.],\n",
            "        [6.]])\n",
            "torch.Size([1599, 11])\n",
            "torch.Size([1599, 1])\n",
            "12.68463984131813\n",
            "6.692981839179993\n",
            "5.26429982483387\n",
            "4.2506261467933655\n",
            "3.4865940511226654\n",
            "2.9260557740926743\n",
            "2.506434954702854\n",
            "2.1743488386273384\n",
            "1.9196989461779594\n",
            "1.7100230306386948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mff54LiQ0_DJ",
        "colab_type": "text"
      },
      "source": [
        "Create dataloaders using TensorDataset and Dataloader from PyTorch. \n",
        "With TensorDataset you can create an iterable dataset by initializing it with the loaded tensors-data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6uFR8NgplBHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "print(train_ds[0:3])\n",
        "# Define data loader\n",
        "batch_size = 100\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTp9WnO_4Bk9",
        "colab_type": "text"
      },
      "source": [
        "# Create Linear regression  model \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4oo4xDnZlBHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lr_model = nn.Linear(in_features=11,out_features=1)\n",
        "optimizer = torch.optim.SGD(lr_model.parameters(),lr=0.0001)\n",
        "criterion = nn.MSELoss(size_average=True)\n",
        "from torch.utils.data import TensorDataset, DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LqRjcwh4NWr",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8knyUb7YlBHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "epochs = 10\n",
        "for i in range(epochs):\n",
        "    average_loss = 0.0\n",
        "    for batch_index, (x,y) in enumerate(train_dl):\n",
        "        preds = lr_model(x)\n",
        "        loss = criterion(preds,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        average_loss +=loss.item()\n",
        "    print(f'Average loss = {average_loss/len(train_dl)}')\n",
        "\n",
        "\n",
        "#print(lr_model.weight.data)\n",
        "#print(lr_model.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}