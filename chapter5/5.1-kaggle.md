# 5.1 Introduction to kaggle
## 5.1.1 Kaggle
### Platform Introduction
Kaggle was founded by co-founder and CEO Anthony Goldbloom in Melbourne in 2010. It mainly provides developers and data scientists with a platform for holding machine learning competitions, hosting databases, and writing and sharing code. . The platform has attracted the attention of 800,000 data scientists, and these user resources may be the main factor that attracts Google.

This paragraph is taken from [Baidu Encyclopedia](https://baike.baidu.com/item/Kaggle/10449376)

In layman's terms, Kaggle has a variety of high-quality data sets, and based on these data sets, some large companies will sponsor to hold some algorithm competitions, and they can also be discussed through the community during the competition (including sharing in the competition) , Q&A, and share with the top solution after the game). This makes the world's top players interested in participating in the competition, because the rewards are not only bonuses but also fame. At the same time, kaggle is also very friendly to Mengxin. You can learn a lot of knowledge and top solutions in the community.

### Competition Introduction
The kaggle website is in pure English. We can divide the competition into 2 categories:

1. Competitions: The purpose of the competition is very simple. It is required to use the data of the questioning party to complete the specified tasks within a specified time (usually 2-3 months). If you are lucky enough to win the competition, you will not only get bonuses, but also models. Will be used by competition sponsors in business practice, winners will directly enter the sponsoring company's work or get some major conference invitations, published papers, etc.
2. Datasets datasets: In order to solve certain problems, the sponsors have released some of their internal desensitization data for free. Everyone can use these datasets for research to improve existing models or optimize current There are problematic solutions, but these models or solutions can be kept private, so this part does not provide bonuses, but can be compared with other people's solutions.

## 5.1.2 Kaggle section introduction
### Data

Needless to say, this is the data we use.

This module needs to be read by recognition. It introduces the method of data generation, storage format, and the meaning of each field. If the data scale is large and you don’t have a server with enough memory to hold it, you may not be able to play this game or use this data set; we also need to pay attention to his data type, such as image data, then we have to use a deep neural network If you are not familiar with this aspect or if you don’t have a GPU available, you definitely can’t participate in this competition. Don’t try to use the CPU to do CNN calculations.
We can divide the competitions on the kaggle platform into the following 4 categories:

1. Mining: Facing structured data, that is, tabular data, it includes all kinds of forecasting problems (forecasting sales, click-through rate, recommendation ranking, etc.). The main commonality is to understand the data, understand the problems, and learn from the data. Find useful information to predict, the outcome of this type of problem is more on the characteristics, so this part is the world of tree models such as the famous xgboost.
2. Image: For images, CNN is definitely needed. Although this part can be done with transfer learning, it is also necessary to obtain a large amount of computing power for ranking, because there will be a lot of times to verify and fine-tune.
3. Voice: I don’t know much about this part, so I won’t be ugly
4. NLP: After BERT comes out, various pre-training weights will be of great help to the competition in this area

### Rules

competition rules. This must be seen, whether it is a cute new or a great god, the rules of the game still have to be followed.

Number of submissions: The maximum number of submissions allowed per day will be stated here, usually 5 times. If the duration of a competition is three months, then the total number of submissions is almost 5×90=450 times.

In order to avoid the limit on the number of submissions or to "save the number of submissions", many people register a small account, which is called multiple accounts, which will be detected by Kaggle's anti-cheat system. After the game is over, the preliminary ranking will be announced first, and then the anti-cheating system on the kaggle platform will start to operate. About two or three days later, all teams convicted of cheating will be directly removed from the rankings, and months of hard work will be lost! So this operation must be prohibited.

The other is private sharing of codes and results outside the group, which is also expressly prohibited. After the team is formed, the team members can share it, or through the open kernel or discussion area. Similarly, if it is detected that different teams or individuals have similar results, they will also be removed from the final list.
### Team

When participating in the competition, you can initiate a team invitation to others, or accept other people’s invitations. The three heads are like Zhuge Liang. Needless to say, the benefits of teaming are up to 4 people per team, and the code can be shared. This is equivalent to a 4 times increase in computing power.

The other thing is to give the team a sulky name.

### Kernels

. . . (I don't know how to translate, it is the core code in short). Supports Python scripts .py and .ipynb, and R scripts .R and .ipynb.

It is divided into public kernel and private kernel.

The public kernel is public, and everyone can see it. You can learn a lot from it. Of course, you can also share solutions or opinions by publicizing your kernel.

The private kernel is your own, invisible to others, you can share it with members of the group.

To make it easier for everyone to play the game, kaggle provides some computing resources. Each kernel of kaggle users can have 16G of memory and 4-core CPU, which is enough for most games. In addition, a GPU is provided. You can choose to turn on the GPU when you create a new kernel. However, when you turn on the GPU, the CPU and memory resources will be less. This will be described in detail in the later guide.


### Discussion

Discussion area, where everyone will share opinions, discuss issues, and even find teammates.

Kaggle's sharing atmosphere is very good, and it is very friendly to Mengxin. Everyone kept sharing their new discoveries throughout the course of the competition, and a lot of useful information was obtained here.
For a novice, keep track of the kernel area and discussion area every day, and have enough time to try their ideas, and you should get a good ranking.
After the game, some big cows even shared all the methods and tricks they used to win.

### Leaderboard

The ranking area is divided into public LB and private LB. The contestant will use a part of the test data set (for example, 30%) as the public LB score and ranking, and the remaining part as the private LB (that is, the final result) score and ranking.

You can submit and view the score and ranking of your answer in the public LB every day. Before the end of the game, you need to choose two submissions as your final answer. After the game, the platform will calculate the private LB score of your answer and automatically Pick the one with the highest score as your final score.

In the discussion area, you will often hear everyone discussing CV score and LB score, which refer to the local cross-validation score of your model and the public LB score after submission.

Shake up: Public LB scores may be very different from private LB scores. Before the results of the game are announced, you may be ranked in the top ten. After the results of the game are announced, you find that you have fallen to thousands of places. This is the so-called shake up. Fit, this needs to be paid attention to during training.


## 5.1.3 Ranking mechanism of Kaggle competition
Under normal circumstances, the ranking is based on accuracy. After all, the accuracy of our model is the first criterion.

For the competition, before the end of the competition, contestants can submit up to 5 test set prediction results per day. Each submission of the results will get the latest temporary ranking results, until the end of the competition to obtain the final ranking, Kaggle will take out 25%-33% of the results submitted by the participants, and according to the accuracy rate for temporary ranking. At the end of the competition, participants can specify several submitted results, Kaggle removes the part previously used for temporary rankings, and uses the accuracy of the remaining data to synthesize the final ranking.

Therefore, in the part of the data used for the final ranking during the competition, the contestants never get feedback on the accuracy. In this way, over-fitting of participating models is avoided to a certain extent, and a model that takes into account both accuracy and generalization ability is selected.

## 5.1.4 Kaggle Wool Guide
~~Kaggle provides free access to the NVidia K80 GPU in the kernel. My personal understanding is equivalent to the level of 1060 or 1070. ~~
We can turn on the GPU in the Setting option at the bottom right of the Kernel interface, so that we can use free GPU resources

![GPU Settings](kaggle.png)

~~Kaggle only provides 6 hours of continuous GPU usage time~~, although it is not enough for large data calculations, but for research, these are enough, such as CIFAR-10, which we often use in image recognition Picture classification, generally training for about 2 hours can get a more accurate model, which has been communicated for introductory learning.


Update: Now the GPU provided by Kaggle is P100, which is limited to 30 hours of free use per week, and you can also connect to Google's colab, which is definitely enough for our learning and testing.

## 5.1.5 Some other data competition platforms
In addition to Kaggle, there are actually many similar platforms;

[DrivenData]( https://www.drivendata.org/)

[CrowdANALYTIX]( https://www.crowdanalytix.com/community)

[InnoCentive]( https://www.innocentive.com/our-solvers/)

[TundIT]( https://towardsdatascience.com/top-competitive-data-science-platforms-other-than-kaggle-2995e9dad93c)

[Codalab]( https://competitions.codalab.org/)

[Analytics Vidhya]( https://datahack.analyticsvidhya.com/)

[CrowdAI]( https://www.crowdai.org/challenges)

[Numerai]( https://numer.ai/rounds)

[Data Science Challenge]( https://www.datasciencechallenge.org/)

[KDD Cup]( https://www.kdd.org/kdd2019/kdd-cup)

[天池]( https://tianchi.aliyun.com/competition/gameList/activeList)

[Tencent Advertising Algorithm Competition]( https://algo.qq.com)